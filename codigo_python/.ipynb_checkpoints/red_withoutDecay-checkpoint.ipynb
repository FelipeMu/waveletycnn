{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias para trabajar con la red neuronal y procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "##################### Convertir matrices de .mat a .npy ##########################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_pam_mat' # matrices en formato .mat\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_vsc_mat' # matrices en formato .mat\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python' # INPUT PARA LA RED\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python' # OUTPUT O SALIDAS ESPERADAS PARA LA RED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, 31):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vsc_dir, output_vsc_dir, 'matrix_complex_vsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################<br>\n",
    "##################### Conversion a tensor tridimensional ##########################<br>\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python'\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python'\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################\n",
    "PREPROCESAMIENTO ANTES DE NORMALIZACIÓN DE MATRICES\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÁLCULO DE LA MEDIA - PAM & VSC (la media se calcula teniendo en cuenta todas las matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acumuladores para calcular la media de cada matriz (real e imaginaria) y la desviacion estandar\n",
    "\n",
    "#==========================\n",
    "#=== PAM SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_pam = 0\n",
    "media_real_pam = 0\n",
    "\n",
    "sumatoria_imag_pam = 0\n",
    "media_imag_pam = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_pam = 0\n",
    "sumatoria_imag_cuadrada_pam = 0\n",
    "\n",
    "desv_real_pam = 0\n",
    "desv_imag_pam = 0\n",
    "\n",
    "\n",
    "#==========================\n",
    "#=== VSC SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_vsc = 0\n",
    "media_real_vsc = 0\n",
    "\n",
    "sumatoria_imag_vsc = 0\n",
    "media_imag_vsc = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_vsc = 0\n",
    "sumatoria_imag_cuadrada_vsc = 0\n",
    "\n",
    "desv_real_vsc = 0\n",
    "desv_imag_vsc = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  PAM  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_real_pam(matriz):\n",
    "    global sumatoria_real_pam\n",
    "    sumatoria_real_pam = sumatoria_real_pam + np.sum(matriz)\n",
    "    #print(sumatoria_real_pam)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_real_cuadrada_pam(matriz):\n",
    "    global sumatoria_real_cuadrada_pam, media_real_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_pam = sumatoria_real_cuadrada_pam + (elemento - media_real_pam)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_imag_pam(matriz):\n",
    "    global sumatoria_imag_pam\n",
    "    sumatoria_imag_pam = sumatoria_imag_pam + np.sum(matriz)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_imag_cuadrada_pam(matriz):\n",
    "    global sumatoria_imag_cuadrada_pam, media_imag_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_pam = sumatoria_imag_cuadrada_pam + (elemento - media_imag_pam)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  VSC  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_real_vsc(matriz):\n",
    "    global sumatoria_real_vsc\n",
    "    sumatoria_real_vsc = sumatoria_real_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_real_cuadrada_vsc(matriz):\n",
    "    global sumatoria_real_cuadrada_vsc, media_real_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_vsc = sumatoria_real_cuadrada_vsc + (elemento - media_real_vsc)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_imag_vsc(matriz):\n",
    "    global sumatoria_imag_vsc\n",
    "    sumatoria_imag_vsc = sumatoria_imag_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_imag_cuadrada_vsc(matriz):\n",
    "    global sumatoria_imag_cuadrada_vsc, media_imag_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_vsc = sumatoria_imag_cuadrada_vsc + (elemento - media_imag_vsc)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORRER MATRICES & CÁLCULO DE LA MEDIA  MATRIZ PAM (Presion Arterial Media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_pam(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_pam(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a pam signals: Se suman cada unos de los coeficientes de cada matriz real pam (archivos x filas x columnas)\n",
    "num_files_input_pam_dir = sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.npy'))\n",
    "filas_matriz, columnas_matriz = matriz_compleja.shape\n",
    "coefs_totales =  num_files_input_pam_dir * filas_matriz * columnas_matriz # N\n",
    "media_real_pam = sumatoria_real_pam / coefs_totales # MEDIA REAL\n",
    "media_imag_pam = sumatoria_imag_pam / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ PAM (Presion Arterial Media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_pam(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_pam(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_pam = np.square(sumatoria_real_cuadrada_pam/coefs_totales)\n",
    "desv_imag_pam = np.square(sumatoria_imag_cuadrada_pam/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#==============================================================================================================================\n",
    "#==============================================================================================================================\n",
    "#=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORRER MATRICES & CÁLCULO DE LA MEDIA MATRIZ VSC (Velocidad Sanguínea Cerebral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4158453015843406e-13\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_vsc(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_vsc(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a vsc signals: Se suman cada unos de los coeficientes de cada matriz real vsc (archivos x filas x columnas)\n",
    "num_files_input_vsc_dir = sum(1 for filename in os.listdir(input_vsc_dir) if filename.endswith('.npy'))\n",
    "media_real_vsc = sumatoria_real_vsc / coefs_totales # MEDIA REAL\n",
    "media_imag_vsc = sumatoria_imag_vsc / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ VSC (Velocidad Sanguínea Cerebral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_vsc(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_vsc(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_vsc = np.square(sumatoria_real_cuadrada_vsc/coefs_totales)\n",
    "desv_imag_vsc = np.square(sumatoria_imag_cuadrada_vsc/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING_ PROBANDO NORMALIZACION MIN-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_real_pam = 1000000\n",
    "min_imag_pam = 1000000\n",
    "max_real_pam = -100\n",
    "max_imag_pam = -100\n",
    "\n",
    "min_real_vsc = 1000000\n",
    "min_imag_vsc = 1000000\n",
    "max_real_vsc = -100\n",
    "max_imag_vsc = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PAM\n",
    "def encontrar_min_pam(matriz):\n",
    "    global min_real_pam, min_imag_pam\n",
    "    if np.min(matriz.real) < min_real_pam:\n",
    "        min_real_pam = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_pam:\n",
    "        min_imag_pam = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_pam(matriz):\n",
    "    global max_real_pam, max_imag_pam\n",
    "    if np.max(matriz.real) > max_real_pam:\n",
    "        max_real_pam = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_pam:\n",
    "        max_imag_pam = np.max(matriz.imag)\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#####################################\n",
    "###########\n",
    "#VSC\n",
    "\n",
    "def encontrar_min_vsc(matriz):\n",
    "    global min_real_vsc, min_imag_vsc\n",
    "    if np.min(matriz.real) < min_real_vsc:\n",
    "        min_real_vsc = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_vsc:\n",
    "        min_imag_vsc = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_vsc(matriz):\n",
    "    global max_real_vsc, max_imag_vsc\n",
    "    if np.max(matriz.real) > max_real_vsc:\n",
    "        max_real_vsc = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_vsc:\n",
    "        max_imag_vsc = np.max(matriz.imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MIN-MAX\n",
    "#PAM\n",
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_pam(matriz_compleja)\n",
    "        encontrar_max_pam(matriz_compleja)\n",
    "\n",
    "#VSC\n",
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_vsc(matriz_compleja)\n",
    "        encontrar_max_vsc(matriz_compleja)\n",
    "        \n",
    "\n",
    "print(min_real_pam)\n",
    "print(min_imag_pam)\n",
    "print(max_real_pam)\n",
    "print(max_imag_pam)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(min_real_vsc)\n",
    "print(min_imag_vsc)\n",
    "print(max_real_vsc)\n",
    "print(max_imag_vsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a=10\n",
    "def suma(elemento,a):\n",
    "    a= a+elemento\n",
    "    \n",
    "\n",
    "e=7\n",
    "suma(7,a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####################################################\n",
    "APLICACIÓN DE NORMALIZACION A LAS MATRICES PAM Y VSC\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_pam(matriz_compleja):\n",
    "    global media_real_pam, media_imag_pam desv_real_pam, desv_imag_pam\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_pam) / desv_real_pam # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_pam) / desv_imag_pam # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_vsc(matriz_compleja):\n",
    "    global media_real_vsc, media_imag_vsc desv_real_vsc, desv_imag_vsc\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_vsc) / desv_real_vsc # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_vsc) / desv_imag_vsc # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz pam)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz pam y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_pam(matriz_compleja):\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    norm_real, norm_imag = normalizacion_pam(matriz_compleja)\n",
    "    # Crear input adecuado\n",
    "    datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "\n",
    "\n",
    "    \n",
    "    #datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz vsc)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz vsc y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_vsc(matriz_compleja):\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    norm_real, norm_imag = normalizacion_vsc(matriz_compleja)\n",
    "    # Crear input adecuado\n",
    "    datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "\n",
    "    \n",
    "    \n",
    "    #datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_pam_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja\n",
    "        datos_organizados = procesar_matriz_compleja_pam(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vsc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        output_path = os.path.join(output_vsc_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################<br>\n",
    "################## Verificacicon de \"shape\" - matrices pam y vsc ##################<br>\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsc_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_vsc = os.listdir(output_vsc_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsc = verificar_shape(output_vsc_dir_check, ejemplo_vsc)\n",
    "print(f\"Shape de {ejemplo_vsc} en {output_vsc_dir_check}: {shape_vsc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "####################### Red Neuronal Profunda: U-net #############################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_npy_files(input_pam_dir) # inputs\n",
    "Y = load_npy_files(output_vsc_dir) # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model_with_l2(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "**HIPERPARAMETROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 500\n",
    "batchsize = 8\n",
    "learning_rate = 0.0001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.3 # 70% entrenamiento & 30% validacion\n",
    "\n",
    "\n",
    "warmup_steps = int(0.20*max_epoch)\n",
    "decay_steps = int(0.80*max_epoch)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red\n",
    "#model = unet_model_with_l2(input_shape, l2_lambda)\n",
    "model = unet_model_with_l2(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing-testing-testing-testing-testing-testing-testing\n",
    "\n",
    "\n",
    "# This function keeps the learning rate at 0.001 for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "'''\n",
    "def scheduler(epoch , lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "'''\n",
    "'''\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < warmup_steps:\n",
    "        return learning_rate * (epoch + 1) / warmup_steps\n",
    "    else:\n",
    "        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(math.pi) * (epoch - warmup_steps) / decay_steps))\n",
    "        decayed = (1 - alpha) * cosine_decay + alpha\n",
    "        return learning_rate * decayed\n",
    "'''\n",
    "\n",
    "decay_cosine = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "def lr_schedule(X):\n",
    "    return float(decay_cosine(X))\n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio en donde se almacenara el modelo\n",
    "save_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/modelos_generados'\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Nombre del archivo del modelo\n",
    "model_name = 'unet_model_decay_coseno_with_normalization_1.keras'\n",
    "\n",
    "# Ruta completa del archivo\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir señal VSC a partir de una señal PAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Funcion para predecir con el modelo entrenado\n",
    "def predict_with_model(model, input_data):\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction\n",
    "\n",
    "# Cargar una matriz de entrada para hacer una predicción \n",
    "input_matrix = X[0:1] \n",
    "# Realizar la predicción\n",
    "predicted_output = predict_with_model(model, input_matrix)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(\"Predicción de la primera muestra de entrada:\")\n",
    "print(predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
