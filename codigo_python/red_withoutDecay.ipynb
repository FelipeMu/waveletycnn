{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias para trabajar con la red neuronal y procesamiento de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "##################### Convertir matrices de .mat a .npy ##########################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_pam_mat' # matrices en formato .mat\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_vsc_mat' # matrices en formato .mat\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python' # INPUT PARA LA RED\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python' # OUTPUT O SALIDAS ESPERADAS PARA LA RED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos a analizar ->  50\n"
     ]
    }
   ],
   "source": [
    "total_files=sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de archivos a analizar -> \",total_files-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_files):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vsc_dir, output_vsc_dir, 'matrix_complex_vsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion a tensor tridimensional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python'\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python'\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################\n",
    "PREPROCESAMIENTO ANTES DE NORMALIZACIÓN DE MATRICES\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CÁLCULO DE LA MEDIA - PAM & VSC (la media se calcula teniendo en cuenta todas las matrices)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acumuladores para calcular la media de cada matriz (real e imaginaria) y la desviacion estandar\n",
    "\n",
    "#==========================\n",
    "#=== PAM SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_pam = 0\n",
    "media_real_pam = 0\n",
    "\n",
    "sumatoria_imag_pam = 0\n",
    "media_imag_pam = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_pam = 0\n",
    "sumatoria_imag_cuadrada_pam = 0\n",
    "\n",
    "desv_real_pam = 0\n",
    "desv_imag_pam = 0\n",
    "\n",
    "\n",
    "#==========================\n",
    "#=== VSC SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_vsc = 0\n",
    "media_real_vsc = 0\n",
    "\n",
    "sumatoria_imag_vsc = 0\n",
    "media_imag_vsc = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_vsc = 0\n",
    "sumatoria_imag_cuadrada_vsc = 0\n",
    "\n",
    "desv_real_vsc = 0\n",
    "desv_imag_vsc = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  PAM  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_real_pam(matriz):\n",
    "    global sumatoria_real_pam\n",
    "    sumatoria_real_pam = sumatoria_real_pam + np.sum(matriz)\n",
    "    #print(sumatoria_real_pam)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_real_cuadrada_pam(matriz):\n",
    "    global sumatoria_real_cuadrada_pam, media_real_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_pam = sumatoria_real_cuadrada_pam + (elemento - media_real_pam)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_imag_pam(matriz):\n",
    "    global sumatoria_imag_pam\n",
    "    sumatoria_imag_pam = sumatoria_imag_pam + np.sum(matriz)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_imag_cuadrada_pam(matriz):\n",
    "    global sumatoria_imag_cuadrada_pam, media_imag_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_pam = sumatoria_imag_cuadrada_pam + (elemento - media_imag_pam)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  VSC  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_real_vsc(matriz):\n",
    "    global sumatoria_real_vsc\n",
    "    sumatoria_real_vsc = sumatoria_real_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_real_cuadrada_vsc(matriz):\n",
    "    global sumatoria_real_cuadrada_vsc, media_real_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_vsc = sumatoria_real_cuadrada_vsc + (elemento - media_real_vsc)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_imag_vsc(matriz):\n",
    "    global sumatoria_imag_vsc\n",
    "    sumatoria_imag_vsc = sumatoria_imag_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_imag_cuadrada_vsc(matriz):\n",
    "    global sumatoria_imag_cuadrada_vsc, media_imag_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_vsc = sumatoria_imag_cuadrada_vsc + (elemento - media_imag_vsc)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA  MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_pam(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_pam(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a pam signals: Se suman cada unos de los coeficientes de cada matriz real pam (archivos x filas x columnas)\n",
    "num_files_input_pam_dir = sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.npy'))\n",
    "filas_matriz, columnas_matriz = matriz_compleja.shape\n",
    "coefs_totales =  num_files_input_pam_dir * filas_matriz * columnas_matriz # N\n",
    "media_real_pam = sumatoria_real_pam / coefs_totales # MEDIA REAL\n",
    "media_imag_pam = sumatoria_imag_pam / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_pam(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_pam(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_pam = np.square(sumatoria_real_cuadrada_pam/coefs_totales)\n",
    "desv_imag_pam = np.square(sumatoria_imag_cuadrada_pam/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#==============================================================================================================================\n",
    "#==============================================================================================================================\n",
    "#=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_vsc(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_vsc(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a vsc signals: Se suman cada unos de los coeficientes de cada matriz real vsc (archivos x filas x columnas)\n",
    "num_files_input_vsc_dir = sum(1 for filename in os.listdir(input_vsc_dir) if filename.endswith('.npy'))\n",
    "media_real_vsc = sumatoria_real_vsc / coefs_totales # MEDIA REAL\n",
    "media_imag_vsc = sumatoria_imag_vsc / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_vsc(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_vsc(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_vsc = np.square(sumatoria_real_cuadrada_vsc/coefs_totales)\n",
    "desv_imag_vsc = np.square(sumatoria_imag_cuadrada_vsc/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION MIN-MAX**\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_real_pam = 1000000\n",
    "min_imag_pam = 1000000\n",
    "max_real_pam = -100\n",
    "max_imag_pam = -100\n",
    "\n",
    "min_real_vsc = 1000000\n",
    "min_imag_vsc = 1000000\n",
    "max_real_vsc = -100\n",
    "max_imag_vsc = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PAM: encontrar min y max de matrices reales e imaginarias\n",
    "def encontrar_min_pam(matriz):\n",
    "    global min_real_pam, min_imag_pam\n",
    "    if np.min(matriz.real) < min_real_pam:\n",
    "        min_real_pam = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_pam:\n",
    "        min_imag_pam = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_pam(matriz):\n",
    "    global max_real_pam, max_imag_pam\n",
    "    if np.max(matriz.real) > max_real_pam:\n",
    "        max_real_pam = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_pam:\n",
    "        max_imag_pam = np.max(matriz.imag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "#VSC: encontrar min y max de matrices reales e imaginarias\n",
    "\n",
    "def encontrar_min_vsc(matriz):\n",
    "    global min_real_vsc, min_imag_vsc\n",
    "    if np.min(matriz.real) < min_real_vsc:\n",
    "        min_real_vsc = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_vsc:\n",
    "        min_imag_vsc = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_vsc(matriz):\n",
    "    global max_real_vsc, max_imag_vsc\n",
    "    if np.max(matriz.real) > max_real_vsc:\n",
    "        max_real_vsc = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_vsc:\n",
    "        max_imag_vsc = np.max(matriz.imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MIN-MAX\n",
    "#PAM\n",
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_pam(matriz_compleja)\n",
    "        encontrar_max_pam(matriz_compleja)\n",
    "\n",
    "#VSC\n",
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_vsc(matriz_compleja)\n",
    "        encontrar_max_vsc(matriz_compleja)\n",
    "        \n",
    "\n",
    "print(min_real_pam)\n",
    "print(min_imag_pam)\n",
    "print(max_real_pam)\n",
    "print(max_imag_pam)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(min_real_vsc)\n",
    "print(min_imag_vsc)\n",
    "print(max_real_vsc)\n",
    "print(max_imag_vsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APLICACIÓN DE NORMALIZACION A LAS MATRICES PAM Y VSC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NORMALIZACIÓN MEDIANTE Z-CORE**<br>\n",
    "z = (x - u) / desv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_pam(matriz_compleja):\n",
    "    global media_real_pam, media_imag_pam, desv_real_pam, desv_imag_pam\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_pam) / desv_real_pam # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_pam) / desv_imag_pam # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_vsc(matriz_compleja):\n",
    "    global media_real_vsc, media_imag_vsc, desv_real_vsc, desv_imag_vsc\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_vsc) / desv_real_vsc # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_vsc) / desv_imag_vsc # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NORMALIZACIÓN MEDIANTE MIN - MAX**<br>\n",
    "Ni = (Xi - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz PAM)\n",
    "#Salida: n_real (matriz real de pam normalizada), n_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_pam(matriz_compleja):\n",
    "    global min_real_pam, max_real_pam, min_imag_pam, max_imag_pam\n",
    "    n_real = (matriz_compleja.real - min_real_pam) / (max_real_pam - min_real_pam)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_pam) / (max_imag_pam - min_imag_pam)\n",
    "    return n_real, n_imag\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz VSC)\n",
    "#Salida: n_real (matriz real de vsc normalizada), n_imag (matriz imag de vsc normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz vsc y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_vsc(matriz_compleja):\n",
    "    global min_real_vsc, max_real_vsc,  min_imag_vsc, max_imag_vsc\n",
    "    n_real = (matriz_compleja.real - min_real_vsc) / (max_real_vsc - min_real_vsc)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_vsc) / (max_imag_vsc - min_imag_vsc)\n",
    "    return n_real, n_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES SEGÚN UNA NORMALIZACIÓN Y ORGANIZAR DATOS PARA LA RED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz pam)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz pam y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_pam(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z = (x - u) / desv\n",
    "    norm_real, norm_imag = normalizacion_pam(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi - Xmin) / (Xmax - Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_pam(matriz_compleja)\n",
    "\n",
    "    # Crear input adecuado\n",
    "    datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    #datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz vsc)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz vsc y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_vsc(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z=(x - u)/desv\n",
    "    norm_real, norm_imag = normalizacion_vsc(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi-Xmin)/(Xmax-Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_vsc(matriz_compleja)\n",
    "    \n",
    "    # Crear input adecuado\n",
    "    datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    #datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_pam_dir y procesar matrices mediante una normalización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_pam(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vsc_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        output_path = os.path.join(output_vsc_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificacion de \"shape\" - matrices pam y vsc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_pam_noise_1.npy en D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsc_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vsc_noise_1.npy en D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vsc = os.listdir(output_vsc_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsc = verificar_shape(output_vsc_dir_check, ejemplo_vsc)\n",
    "print(f\"Shape de {ejemplo_vsc} en {output_vsc_dir_check}: {shape_vsc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**|||Red Neuronal Profunda: U-net|||**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "     # verificar orden con que entrar los archivos en X e Y\n",
    "    file_names = [os.path.basename(f) for f in files]\n",
    "    print(f\"Archivos: {file_names}\\n\")\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE DATOS DE ENTRADAS Y SALIDAS PARA LA RED (X: INPUTS; Y: OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos: ['matrix_complex_pam_noise_1.npy', 'matrix_complex_pam_noise_10.npy', 'matrix_complex_pam_noise_11.npy', 'matrix_complex_pam_noise_12.npy', 'matrix_complex_pam_noise_13.npy', 'matrix_complex_pam_noise_14.npy', 'matrix_complex_pam_noise_15.npy', 'matrix_complex_pam_noise_16.npy', 'matrix_complex_pam_noise_17.npy', 'matrix_complex_pam_noise_18.npy', 'matrix_complex_pam_noise_19.npy', 'matrix_complex_pam_noise_2.npy', 'matrix_complex_pam_noise_20.npy', 'matrix_complex_pam_noise_21.npy', 'matrix_complex_pam_noise_22.npy', 'matrix_complex_pam_noise_23.npy', 'matrix_complex_pam_noise_24.npy', 'matrix_complex_pam_noise_25.npy', 'matrix_complex_pam_noise_26.npy', 'matrix_complex_pam_noise_27.npy', 'matrix_complex_pam_noise_28.npy', 'matrix_complex_pam_noise_29.npy', 'matrix_complex_pam_noise_3.npy', 'matrix_complex_pam_noise_30.npy', 'matrix_complex_pam_noise_31.npy', 'matrix_complex_pam_noise_32.npy', 'matrix_complex_pam_noise_33.npy', 'matrix_complex_pam_noise_34.npy', 'matrix_complex_pam_noise_35.npy', 'matrix_complex_pam_noise_36.npy', 'matrix_complex_pam_noise_37.npy', 'matrix_complex_pam_noise_38.npy', 'matrix_complex_pam_noise_39.npy', 'matrix_complex_pam_noise_4.npy', 'matrix_complex_pam_noise_40.npy', 'matrix_complex_pam_noise_41.npy', 'matrix_complex_pam_noise_42.npy', 'matrix_complex_pam_noise_43.npy', 'matrix_complex_pam_noise_44.npy', 'matrix_complex_pam_noise_45.npy', 'matrix_complex_pam_noise_46.npy', 'matrix_complex_pam_noise_47.npy', 'matrix_complex_pam_noise_48.npy', 'matrix_complex_pam_noise_49.npy', 'matrix_complex_pam_noise_5.npy', 'matrix_complex_pam_noise_50.npy', 'matrix_complex_pam_noise_6.npy', 'matrix_complex_pam_noise_7.npy', 'matrix_complex_pam_noise_8.npy', 'matrix_complex_pam_noise_9.npy']\n",
      "\n",
      "Archivos: ['matrix_complex_vsc_noise_1.npy', 'matrix_complex_vsc_noise_10.npy', 'matrix_complex_vsc_noise_11.npy', 'matrix_complex_vsc_noise_12.npy', 'matrix_complex_vsc_noise_13.npy', 'matrix_complex_vsc_noise_14.npy', 'matrix_complex_vsc_noise_15.npy', 'matrix_complex_vsc_noise_16.npy', 'matrix_complex_vsc_noise_17.npy', 'matrix_complex_vsc_noise_18.npy', 'matrix_complex_vsc_noise_19.npy', 'matrix_complex_vsc_noise_2.npy', 'matrix_complex_vsc_noise_20.npy', 'matrix_complex_vsc_noise_21.npy', 'matrix_complex_vsc_noise_22.npy', 'matrix_complex_vsc_noise_23.npy', 'matrix_complex_vsc_noise_24.npy', 'matrix_complex_vsc_noise_25.npy', 'matrix_complex_vsc_noise_26.npy', 'matrix_complex_vsc_noise_27.npy', 'matrix_complex_vsc_noise_28.npy', 'matrix_complex_vsc_noise_29.npy', 'matrix_complex_vsc_noise_3.npy', 'matrix_complex_vsc_noise_30.npy', 'matrix_complex_vsc_noise_31.npy', 'matrix_complex_vsc_noise_32.npy', 'matrix_complex_vsc_noise_33.npy', 'matrix_complex_vsc_noise_34.npy', 'matrix_complex_vsc_noise_35.npy', 'matrix_complex_vsc_noise_36.npy', 'matrix_complex_vsc_noise_37.npy', 'matrix_complex_vsc_noise_38.npy', 'matrix_complex_vsc_noise_39.npy', 'matrix_complex_vsc_noise_4.npy', 'matrix_complex_vsc_noise_40.npy', 'matrix_complex_vsc_noise_41.npy', 'matrix_complex_vsc_noise_42.npy', 'matrix_complex_vsc_noise_43.npy', 'matrix_complex_vsc_noise_44.npy', 'matrix_complex_vsc_noise_45.npy', 'matrix_complex_vsc_noise_46.npy', 'matrix_complex_vsc_noise_47.npy', 'matrix_complex_vsc_noise_48.npy', 'matrix_complex_vsc_noise_49.npy', 'matrix_complex_vsc_noise_5.npy', 'matrix_complex_vsc_noise_50.npy', 'matrix_complex_vsc_noise_6.npy', 'matrix_complex_vsc_noise_7.npy', 'matrix_complex_vsc_noise_8.npy', 'matrix_complex_vsc_noise_9.npy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = load_npy_files(input_pam_dir) # inputs\n",
    "Y = load_npy_files(output_vsc_dir) # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de los inputs (X): (50, 36, 1024, 2)\n",
      "Shape de los outputs (Y): (50, 36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**HIPERPARAMETROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pasos de decaimiento -> 300 pasos.\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batchsize = 8\n",
    "learning_rate = 0.001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.3 # 80% entrenamiento & 20% validacion\n",
    "\n",
    "\n",
    " # alpha: el lr min al que llegara el decaimiento sera el 10% del lr inicia\n",
    "alpha = 0.1\n",
    "# decay steps: Numero de pasos de entrenamiento tras los cuales el learning rate decaera desde su valor inicial hasta el valor final determinado por alpha\n",
    "decay_steps = 300#(int(X.shape[0]/batchsize))*max_epoch \n",
    "print(\"Total pasos de decaimiento ->\",decay_steps, \"pasos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREACIÓN DEL MODELO U-NET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red tensor X = [#inputs, columnas, filas, canales]. Se omite #inputs\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion decaimiento de coseno\n",
    "decay_cosine = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "def lr_schedule(X):\n",
    "    return float(decay_cosine(X))\n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 16.3023 - nmse: 0.9576 - val_loss: 14.9694 - val_nmse: 0.9164 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 14.9118 - nmse: 0.8756 - val_loss: 13.7463 - val_nmse: 0.8414 - lr: 9.9997e-04\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 14.3062 - nmse: 0.8382 - val_loss: 13.4688 - val_nmse: 0.8244 - lr: 9.9989e-04\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 13.9566 - nmse: 0.8169 - val_loss: 13.2531 - val_nmse: 0.8112 - lr: 9.9975e-04\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 13.6077 - nmse: 0.8022 - val_loss: 12.8168 - val_nmse: 0.7844 - lr: 9.9956e-04\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 13.1791 - nmse: 0.7748 - val_loss: 12.2122 - val_nmse: 0.7473 - lr: 9.9931e-04\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 12.5176 - nmse: 0.7344 - val_loss: 12.1694 - val_nmse: 0.7446 - lr: 9.9901e-04\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 12.3683 - nmse: 0.7250 - val_loss: 11.3986 - val_nmse: 0.6974 - lr: 9.9866e-04\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 11.4765 - nmse: 0.6792 - val_loss: 10.3193 - val_nmse: 0.6313 - lr: 9.9825e-04\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 10.4590 - nmse: 0.6066 - val_loss: 9.5772 - val_nmse: 0.5856 - lr: 9.9778e-04\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 9.7250 - nmse: 0.5652 - val_loss: 9.0291 - val_nmse: 0.5521 - lr: 9.9726e-04\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 8.8507 - nmse: 0.5066 - val_loss: 7.6846 - val_nmse: 0.4697 - lr: 9.9669e-04\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 7.7697 - nmse: 0.4467 - val_loss: 6.9289 - val_nmse: 0.4235 - lr: 9.9606e-04\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 6.9797 - nmse: 0.4078 - val_loss: 6.2862 - val_nmse: 0.3841 - lr: 9.9537e-04\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 6.6272 - nmse: 0.3875 - val_loss: 6.5685 - val_nmse: 0.4013 - lr: 9.9464e-04\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 6.8180 - nmse: 0.4056 - val_loss: 6.0189 - val_nmse: 0.3676 - lr: 9.9384e-04\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 6.1195 - nmse: 0.3570 - val_loss: 5.7645 - val_nmse: 0.3520 - lr: 9.9300e-04\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 5.6943 - nmse: 0.3436 - val_loss: 5.1694 - val_nmse: 0.3156 - lr: 9.9210e-04\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 5.3209 - nmse: 0.3001 - val_loss: 4.9228 - val_nmse: 0.3005 - lr: 9.9114e-04\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 5.0526 - nmse: 0.2883 - val_loss: 4.7090 - val_nmse: 0.2874 - lr: 9.9014e-04\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 4.8509 - nmse: 0.2783 - val_loss: 4.4029 - val_nmse: 0.2688 - lr: 9.8907e-04\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 4.5944 - nmse: 0.2627 - val_loss: 4.2330 - val_nmse: 0.2584 - lr: 9.8796e-04\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 4.3865 - nmse: 0.2543 - val_loss: 4.1660 - val_nmse: 0.2543 - lr: 9.8679e-04\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 4.3094 - nmse: 0.2463 - val_loss: 4.0109 - val_nmse: 0.2449 - lr: 9.8557e-04\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 4.0937 - nmse: 0.2403 - val_loss: 3.8623 - val_nmse: 0.2358 - lr: 9.8429e-04\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.9563 - nmse: 0.2409 - val_loss: 3.9237 - val_nmse: 0.2396 - lr: 9.8296e-04\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.8902 - nmse: 0.2200 - val_loss: 3.6686 - val_nmse: 0.2240 - lr: 9.8158e-04\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.6528 - nmse: 0.2100 - val_loss: 3.5654 - val_nmse: 0.2178 - lr: 9.8015e-04\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.5180 - nmse: 0.2007 - val_loss: 3.4213 - val_nmse: 0.2089 - lr: 9.7866e-04\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.4175 - nmse: 0.2033 - val_loss: 3.3641 - val_nmse: 0.2055 - lr: 9.7712e-04\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.3457 - nmse: 0.2000 - val_loss: 3.3076 - val_nmse: 0.2020 - lr: 9.7553e-04\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.2593 - nmse: 0.1891 - val_loss: 3.4270 - val_nmse: 0.2094 - lr: 9.7388e-04\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 3.1223 - nmse: 0.1933 - val_loss: 3.1328 - val_nmse: 0.1913 - lr: 9.7219e-04\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.9225 - nmse: 0.1688 - val_loss: 3.1134 - val_nmse: 0.1902 - lr: 9.7044e-04\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.8150 - nmse: 0.1689 - val_loss: 3.0896 - val_nmse: 0.1887 - lr: 9.6864e-04\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.7149 - nmse: 0.1499 - val_loss: 3.0800 - val_nmse: 0.1880 - lr: 9.6679e-04\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.5932 - nmse: 0.1529 - val_loss: 3.0138 - val_nmse: 0.1840 - lr: 9.6489e-04\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.4773 - nmse: 0.1471 - val_loss: 3.2431 - val_nmse: 0.1980 - lr: 9.6294e-04\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.4898 - nmse: 0.1476 - val_loss: 3.0409 - val_nmse: 0.1857 - lr: 9.6093e-04\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.3447 - nmse: 0.1366 - val_loss: 3.0582 - val_nmse: 0.1867 - lr: 9.5888e-04\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.2852 - nmse: 0.1297 - val_loss: 3.0607 - val_nmse: 0.1868 - lr: 9.5677e-04\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.1735 - nmse: 0.1281 - val_loss: 3.0079 - val_nmse: 0.1834 - lr: 9.5462e-04\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.0608 - nmse: 0.1210 - val_loss: 2.9228 - val_nmse: 0.1784 - lr: 9.5241e-04\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.9447 - nmse: 0.1125 - val_loss: 2.9728 - val_nmse: 0.1815 - lr: 9.5016e-04\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.8947 - nmse: 0.1082 - val_loss: 2.9307 - val_nmse: 0.1789 - lr: 9.4786e-04\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.8001 - nmse: 0.1062 - val_loss: 2.9991 - val_nmse: 0.1829 - lr: 9.4550e-04\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.6575 - nmse: 0.0963 - val_loss: 2.9761 - val_nmse: 0.1816 - lr: 9.4310e-04\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.5756 - nmse: 0.0922 - val_loss: 3.0067 - val_nmse: 0.1835 - lr: 9.4065e-04\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.5026 - nmse: 0.0891 - val_loss: 3.0119 - val_nmse: 0.1838 - lr: 9.3815e-04\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4513 - nmse: 0.0841 - val_loss: 3.0703 - val_nmse: 0.1873 - lr: 9.3561e-04\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4302 - nmse: 0.0818 - val_loss: 3.0560 - val_nmse: 0.1863 - lr: 9.3301e-04\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3148 - nmse: 0.0764 - val_loss: 2.9981 - val_nmse: 0.1829 - lr: 9.3037e-04\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2757 - nmse: 0.0743 - val_loss: 3.0334 - val_nmse: 0.1851 - lr: 9.2768e-04\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2178 - nmse: 0.0735 - val_loss: 3.3731 - val_nmse: 0.2059 - lr: 9.2495e-04\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2425 - nmse: 0.0706 - val_loss: 3.1745 - val_nmse: 0.1936 - lr: 9.2216e-04\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1827 - nmse: 0.0694 - val_loss: 3.2495 - val_nmse: 0.1983 - lr: 9.1934e-04\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1421 - nmse: 0.0659 - val_loss: 3.2025 - val_nmse: 0.1953 - lr: 9.1646e-04\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1054 - nmse: 0.0641 - val_loss: 3.1561 - val_nmse: 0.1926 - lr: 9.1354e-04\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1119 - nmse: 0.0652 - val_loss: 3.2542 - val_nmse: 0.1985 - lr: 9.1057e-04\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.0604 - nmse: 0.0640 - val_loss: 3.1716 - val_nmse: 0.1936 - lr: 9.0756e-04\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.0057 - nmse: 0.0603 - val_loss: 3.0443 - val_nmse: 0.1857 - lr: 9.0451e-04\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.0036 - nmse: 0.0569 - val_loss: 3.0813 - val_nmse: 0.1879 - lr: 9.0141e-04\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.9946 - nmse: 0.0598 - val_loss: 3.3065 - val_nmse: 0.2017 - lr: 8.9826e-04\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.9630 - nmse: 0.0565 - val_loss: 3.2179 - val_nmse: 0.1964 - lr: 8.9508e-04\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8989 - nmse: 0.0536 - val_loss: 3.1582 - val_nmse: 0.1927 - lr: 8.9185e-04\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.9158 - nmse: 0.0541 - val_loss: 3.0677 - val_nmse: 0.1871 - lr: 8.8857e-04\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8686 - nmse: 0.0514 - val_loss: 3.0754 - val_nmse: 0.1876 - lr: 8.8526e-04\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8432 - nmse: 0.0500 - val_loss: 3.1608 - val_nmse: 0.1927 - lr: 8.8190e-04\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8144 - nmse: 0.0464 - val_loss: 3.1041 - val_nmse: 0.1893 - lr: 8.7850e-04\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8056 - nmse: 0.0476 - val_loss: 3.1905 - val_nmse: 0.1947 - lr: 8.7506e-04\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7739 - nmse: 0.0462 - val_loss: 3.1151 - val_nmse: 0.1900 - lr: 8.7157e-04\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7443 - nmse: 0.0434 - val_loss: 3.0665 - val_nmse: 0.1869 - lr: 8.6805e-04\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7195 - nmse: 0.0412 - val_loss: 3.1287 - val_nmse: 0.1908 - lr: 8.6448e-04\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7072 - nmse: 0.0415 - val_loss: 3.2128 - val_nmse: 0.1960 - lr: 8.6088e-04\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6961 - nmse: 0.0413 - val_loss: 3.2682 - val_nmse: 0.1994 - lr: 8.5724e-04\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7032 - nmse: 0.0418 - val_loss: 3.2162 - val_nmse: 0.1961 - lr: 8.5355e-04\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6840 - nmse: 0.0410 - val_loss: 3.1430 - val_nmse: 0.1916 - lr: 8.4983e-04\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6551 - nmse: 0.0375 - val_loss: 3.0869 - val_nmse: 0.1882 - lr: 8.4607e-04\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6511 - nmse: 0.0385 - val_loss: 3.0661 - val_nmse: 0.1869 - lr: 8.4227e-04\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6407 - nmse: 0.0372 - val_loss: 3.0754 - val_nmse: 0.1874 - lr: 8.3844e-04\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6419 - nmse: 0.0373 - val_loss: 3.1989 - val_nmse: 0.1951 - lr: 8.3457e-04\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6225 - nmse: 0.0366 - val_loss: 3.1369 - val_nmse: 0.1913 - lr: 8.3066e-04\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5966 - nmse: 0.0346 - val_loss: 3.0792 - val_nmse: 0.1877 - lr: 8.2671e-04\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5746 - nmse: 0.0338 - val_loss: 3.1367 - val_nmse: 0.1912 - lr: 8.2273e-04\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5760 - nmse: 0.0338 - val_loss: 3.1065 - val_nmse: 0.1894 - lr: 8.1871e-04\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.5806 - nmse: 0.0347 - val_loss: 3.1690 - val_nmse: 0.1933 - lr: 8.1466e-04\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.5812 - nmse: 0.0340 - val_loss: 3.1424 - val_nmse: 0.1916 - lr: 8.1057e-04\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5506 - nmse: 0.0330 - val_loss: 3.2440 - val_nmse: 0.1979 - lr: 8.0645e-04\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5401 - nmse: 0.0312 - val_loss: 3.1123 - val_nmse: 0.1898 - lr: 8.0230e-04\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5158 - nmse: 0.0309 - val_loss: 3.1611 - val_nmse: 0.1928 - lr: 7.9811e-04\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5103 - nmse: 0.0306 - val_loss: 3.2412 - val_nmse: 0.1977 - lr: 7.9389e-04\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5084 - nmse: 0.0291 - val_loss: 3.1673 - val_nmse: 0.1931 - lr: 7.8964e-04\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4853 - nmse: 0.0285 - val_loss: 3.1180 - val_nmse: 0.1901 - lr: 7.8536e-04\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4851 - nmse: 0.0286 - val_loss: 3.1514 - val_nmse: 0.1922 - lr: 7.8104e-04\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5013 - nmse: 0.0297 - val_loss: 3.0824 - val_nmse: 0.1879 - lr: 7.7670e-04\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5067 - nmse: 0.0303 - val_loss: 3.1844 - val_nmse: 0.1942 - lr: 7.7232e-04\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5213 - nmse: 0.0311 - val_loss: 3.2721 - val_nmse: 0.1995 - lr: 7.6791e-04\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5157 - nmse: 0.0300 - val_loss: 3.1513 - val_nmse: 0.1921 - lr: 7.6348e-04\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4750 - nmse: 0.0270 - val_loss: 3.1391 - val_nmse: 0.1914 - lr: 7.5901e-04\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4752 - nmse: 0.0278 - val_loss: 3.2107 - val_nmse: 0.1958 - lr: 7.5452e-04\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4668 - nmse: 0.0276 - val_loss: 3.2015 - val_nmse: 0.1952 - lr: 7.5000e-04\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4593 - nmse: 0.0261 - val_loss: 3.1525 - val_nmse: 0.1923 - lr: 7.4545e-04\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4358 - nmse: 0.0256 - val_loss: 3.1573 - val_nmse: 0.1925 - lr: 7.4088e-04\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4319 - nmse: 0.0250 - val_loss: 3.1678 - val_nmse: 0.1932 - lr: 7.3628e-04\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4250 - nmse: 0.0254 - val_loss: 3.1851 - val_nmse: 0.1943 - lr: 7.3165e-04\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4331 - nmse: 0.0254 - val_loss: 3.1985 - val_nmse: 0.1950 - lr: 7.2700e-04\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4350 - nmse: 0.0250 - val_loss: 3.1862 - val_nmse: 0.1944 - lr: 7.2232e-04\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.4508 - nmse: 0.0264 - val_loss: 3.1151 - val_nmse: 0.1900 - lr: 7.1762e-04\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4321 - nmse: 0.0260 - val_loss: 3.1742 - val_nmse: 0.1935 - lr: 7.1289e-04\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4352 - nmse: 0.0252 - val_loss: 3.2137 - val_nmse: 0.1960 - lr: 7.0814e-04\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4133 - nmse: 0.0243 - val_loss: 3.1752 - val_nmse: 0.1936 - lr: 7.0337e-04\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4101 - nmse: 0.0241 - val_loss: 3.2045 - val_nmse: 0.1955 - lr: 6.9857e-04\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4060 - nmse: 0.0236 - val_loss: 3.1597 - val_nmse: 0.1926 - lr: 6.9376e-04\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4058 - nmse: 0.0238 - val_loss: 3.1216 - val_nmse: 0.1903 - lr: 6.8892e-04\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4294 - nmse: 0.0255 - val_loss: 3.1498 - val_nmse: 0.1921 - lr: 6.8406e-04\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4067 - nmse: 0.0232 - val_loss: 3.2001 - val_nmse: 0.1951 - lr: 6.7918e-04\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3941 - nmse: 0.0234 - val_loss: 3.2875 - val_nmse: 0.2005 - lr: 6.7429e-04\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4002 - nmse: 0.0232 - val_loss: 3.2602 - val_nmse: 0.1989 - lr: 6.6937e-04\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3876 - nmse: 0.0225 - val_loss: 3.1803 - val_nmse: 0.1939 - lr: 6.6443e-04\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3764 - nmse: 0.0213 - val_loss: 3.1348 - val_nmse: 0.1911 - lr: 6.5948e-04\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3604 - nmse: 0.0214 - val_loss: 3.1794 - val_nmse: 0.1939 - lr: 6.5451e-04\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3630 - nmse: 0.0213 - val_loss: 3.1943 - val_nmse: 0.1948 - lr: 6.4952e-04\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3593 - nmse: 0.0209 - val_loss: 3.1436 - val_nmse: 0.1917 - lr: 6.4452e-04\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3488 - nmse: 0.0206 - val_loss: 3.1730 - val_nmse: 0.1934 - lr: 6.3950e-04\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3461 - nmse: 0.0200 - val_loss: 3.1384 - val_nmse: 0.1913 - lr: 6.3446e-04\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3406 - nmse: 0.0200 - val_loss: 3.1394 - val_nmse: 0.1914 - lr: 6.2941e-04\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3408 - nmse: 0.0197 - val_loss: 3.1460 - val_nmse: 0.1918 - lr: 6.2434e-04\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3362 - nmse: 0.0199 - val_loss: 3.1736 - val_nmse: 0.1935 - lr: 6.1927e-04\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3393 - nmse: 0.0197 - val_loss: 3.1813 - val_nmse: 0.1940 - lr: 6.1418e-04\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3257 - nmse: 0.0188 - val_loss: 3.1883 - val_nmse: 0.1945 - lr: 6.0907e-04\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3189 - nmse: 0.0188 - val_loss: 3.1776 - val_nmse: 0.1938 - lr: 6.0396e-04\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3203 - nmse: 0.0187 - val_loss: 3.1621 - val_nmse: 0.1928 - lr: 5.9883e-04\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3160 - nmse: 0.0187 - val_loss: 3.1709 - val_nmse: 0.1933 - lr: 5.9369e-04\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3172 - nmse: 0.0192 - val_loss: 3.1714 - val_nmse: 0.1934 - lr: 5.8854e-04\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3161 - nmse: 0.0188 - val_loss: 3.1691 - val_nmse: 0.1932 - lr: 5.8338e-04\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3097 - nmse: 0.0181 - val_loss: 3.1782 - val_nmse: 0.1938 - lr: 5.7822e-04\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3059 - nmse: 0.0181 - val_loss: 3.2331 - val_nmse: 0.1972 - lr: 5.7304e-04\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3069 - nmse: 0.0180 - val_loss: 3.2172 - val_nmse: 0.1962 - lr: 5.6786e-04\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2997 - nmse: 0.0175 - val_loss: 3.1484 - val_nmse: 0.1920 - lr: 5.6267e-04\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2932 - nmse: 0.0172 - val_loss: 3.1893 - val_nmse: 0.1945 - lr: 5.5747e-04\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2880 - nmse: 0.0165 - val_loss: 3.1707 - val_nmse: 0.1933 - lr: 5.5226e-04\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2919 - nmse: 0.0169 - val_loss: 3.1803 - val_nmse: 0.1939 - lr: 5.4705e-04\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2856 - nmse: 0.0163 - val_loss: 3.2028 - val_nmse: 0.1954 - lr: 5.4184e-04\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2855 - nmse: 0.0169 - val_loss: 3.1842 - val_nmse: 0.1941 - lr: 5.3662e-04\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2827 - nmse: 0.0164 - val_loss: 3.2000 - val_nmse: 0.1951 - lr: 5.3140e-04\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2820 - nmse: 0.0165 - val_loss: 3.2603 - val_nmse: 0.1988 - lr: 5.2617e-04\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2829 - nmse: 0.0168 - val_loss: 3.2151 - val_nmse: 0.1960 - lr: 5.2094e-04\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2799 - nmse: 0.0166 - val_loss: 3.1900 - val_nmse: 0.1945 - lr: 5.1571e-04\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2842 - nmse: 0.0165 - val_loss: 3.2118 - val_nmse: 0.1959 - lr: 5.1047e-04\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2919 - nmse: 0.0171 - val_loss: 3.1876 - val_nmse: 0.1944 - lr: 5.0524e-04\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2870 - nmse: 0.0166 - val_loss: 3.1721 - val_nmse: 0.1934 - lr: 5.0000e-04\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2725 - nmse: 0.0160 - val_loss: 3.2336 - val_nmse: 0.1972 - lr: 4.9476e-04\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2695 - nmse: 0.0160 - val_loss: 3.2030 - val_nmse: 0.1953 - lr: 4.8953e-04\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2638 - nmse: 0.0151 - val_loss: 3.2238 - val_nmse: 0.1965 - lr: 4.8429e-04\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2627 - nmse: 0.0156 - val_loss: 3.2291 - val_nmse: 0.1969 - lr: 4.7906e-04\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2587 - nmse: 0.0153 - val_loss: 3.2013 - val_nmse: 0.1952 - lr: 4.7383e-04\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2576 - nmse: 0.0152 - val_loss: 3.2139 - val_nmse: 0.1960 - lr: 4.6860e-04\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2551 - nmse: 0.0153 - val_loss: 3.2178 - val_nmse: 0.1962 - lr: 4.6338e-04\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2546 - nmse: 0.0152 - val_loss: 3.2326 - val_nmse: 0.1971 - lr: 4.5816e-04\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2512 - nmse: 0.0149 - val_loss: 3.2415 - val_nmse: 0.1977 - lr: 4.5295e-04\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2566 - nmse: 0.0153 - val_loss: 3.2364 - val_nmse: 0.1974 - lr: 4.4774e-04\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2551 - nmse: 0.0151 - val_loss: 3.2472 - val_nmse: 0.1980 - lr: 4.4253e-04\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2519 - nmse: 0.0145 - val_loss: 3.2086 - val_nmse: 0.1956 - lr: 4.3733e-04\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2522 - nmse: 0.0148 - val_loss: 3.2367 - val_nmse: 0.1974 - lr: 4.3214e-04\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2521 - nmse: 0.0148 - val_loss: 3.2590 - val_nmse: 0.1988 - lr: 4.2696e-04\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2509 - nmse: 0.0147 - val_loss: 3.2598 - val_nmse: 0.1988 - lr: 4.2178e-04\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2498 - nmse: 0.0149 - val_loss: 3.2156 - val_nmse: 0.1961 - lr: 4.1662e-04\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2492 - nmse: 0.0146 - val_loss: 3.2261 - val_nmse: 0.1967 - lr: 4.1146e-04\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2489 - nmse: 0.0150 - val_loss: 3.2156 - val_nmse: 0.1960 - lr: 4.0631e-04\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2467 - nmse: 0.0147 - val_loss: 3.2095 - val_nmse: 0.1957 - lr: 4.0117e-04\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2465 - nmse: 0.0146 - val_loss: 3.2403 - val_nmse: 0.1976 - lr: 3.9604e-04\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2411 - nmse: 0.0140 - val_loss: 3.2195 - val_nmse: 0.1963 - lr: 3.9093e-04\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2351 - nmse: 0.0138 - val_loss: 3.2489 - val_nmse: 0.1981 - lr: 3.8582e-04\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2353 - nmse: 0.0139 - val_loss: 3.2320 - val_nmse: 0.1971 - lr: 3.8073e-04\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2350 - nmse: 0.0139 - val_loss: 3.2570 - val_nmse: 0.1986 - lr: 3.7566e-04\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2378 - nmse: 0.0141 - val_loss: 3.2637 - val_nmse: 0.1991 - lr: 3.7059e-04\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2338 - nmse: 0.0140 - val_loss: 3.2347 - val_nmse: 0.1972 - lr: 3.6554e-04\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2293 - nmse: 0.0135 - val_loss: 3.2060 - val_nmse: 0.1955 - lr: 3.6050e-04\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2302 - nmse: 0.0136 - val_loss: 3.1940 - val_nmse: 0.1947 - lr: 3.5548e-04\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2279 - nmse: 0.0132 - val_loss: 3.2188 - val_nmse: 0.1963 - lr: 3.5048e-04\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2245 - nmse: 0.0133 - val_loss: 3.2692 - val_nmse: 0.1993 - lr: 3.4549e-04\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2230 - nmse: 0.0134 - val_loss: 3.2401 - val_nmse: 0.1976 - lr: 3.4052e-04\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2219 - nmse: 0.0133 - val_loss: 3.2289 - val_nmse: 0.1969 - lr: 3.3557e-04\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2240 - nmse: 0.0133 - val_loss: 3.2184 - val_nmse: 0.1962 - lr: 3.3063e-04\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2204 - nmse: 0.0131 - val_loss: 3.2735 - val_nmse: 0.1996 - lr: 3.2571e-04\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2181 - nmse: 0.0132 - val_loss: 3.2310 - val_nmse: 0.1970 - lr: 3.2082e-04\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2189 - nmse: 0.0130 - val_loss: 3.2454 - val_nmse: 0.1979 - lr: 3.1594e-04\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2159 - nmse: 0.0125 - val_loss: 3.2273 - val_nmse: 0.1968 - lr: 3.1108e-04\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2144 - nmse: 0.0126 - val_loss: 3.2400 - val_nmse: 0.1976 - lr: 3.0624e-04\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2156 - nmse: 0.0123 - val_loss: 3.2499 - val_nmse: 0.1982 - lr: 3.0143e-04\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2163 - nmse: 0.0126 - val_loss: 3.2158 - val_nmse: 0.1961 - lr: 2.9663e-04\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2143 - nmse: 0.0126 - val_loss: 3.2425 - val_nmse: 0.1977 - lr: 2.9186e-04\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2131 - nmse: 0.0128 - val_loss: 3.2537 - val_nmse: 0.1984 - lr: 2.8711e-04\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2155 - nmse: 0.0126 - val_loss: 3.2923 - val_nmse: 0.2008 - lr: 2.8238e-04\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2160 - nmse: 0.0130 - val_loss: 3.2693 - val_nmse: 0.1994 - lr: 2.7768e-04\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2115 - nmse: 0.0124 - val_loss: 3.2492 - val_nmse: 0.1981 - lr: 2.7300e-04\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2087 - nmse: 0.0124 - val_loss: 3.2352 - val_nmse: 0.1973 - lr: 2.6835e-04\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2060 - nmse: 0.0120 - val_loss: 3.2496 - val_nmse: 0.1981 - lr: 2.6372e-04\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2049 - nmse: 0.0119 - val_loss: 3.2476 - val_nmse: 0.1980 - lr: 2.5912e-04\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2027 - nmse: 0.0118 - val_loss: 3.2307 - val_nmse: 0.1970 - lr: 2.5455e-04\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2048 - nmse: 0.0120 - val_loss: 3.2305 - val_nmse: 0.1970 - lr: 2.5000e-04\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2031 - nmse: 0.0119 - val_loss: 3.2525 - val_nmse: 0.1983 - lr: 2.4548e-04\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2001 - nmse: 0.0117 - val_loss: 3.2559 - val_nmse: 0.1985 - lr: 2.4099e-04\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1994 - nmse: 0.0117 - val_loss: 3.2510 - val_nmse: 0.1982 - lr: 2.3652e-04\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1987 - nmse: 0.0117 - val_loss: 3.2553 - val_nmse: 0.1985 - lr: 2.3209e-04\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1983 - nmse: 0.0118 - val_loss: 3.2670 - val_nmse: 0.1992 - lr: 2.2768e-04\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1987 - nmse: 0.0117 - val_loss: 3.2516 - val_nmse: 0.1983 - lr: 2.2330e-04\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1971 - nmse: 0.0115 - val_loss: 3.2487 - val_nmse: 0.1981 - lr: 2.1896e-04\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1957 - nmse: 0.0116 - val_loss: 3.2673 - val_nmse: 0.1992 - lr: 2.1464e-04\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1967 - nmse: 0.0114 - val_loss: 3.2427 - val_nmse: 0.1977 - lr: 2.1036e-04\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1955 - nmse: 0.0113 - val_loss: 3.2300 - val_nmse: 0.1969 - lr: 2.0611e-04\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1974 - nmse: 0.0115 - val_loss: 3.2491 - val_nmse: 0.1981 - lr: 2.0189e-04\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1952 - nmse: 0.0116 - val_loss: 3.2703 - val_nmse: 0.1994 - lr: 1.9770e-04\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1932 - nmse: 0.0114 - val_loss: 3.2517 - val_nmse: 0.1983 - lr: 1.9355e-04\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1932 - nmse: 0.0113 - val_loss: 3.2544 - val_nmse: 0.1984 - lr: 1.8943e-04\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1928 - nmse: 0.0114 - val_loss: 3.2731 - val_nmse: 0.1996 - lr: 1.8534e-04\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1929 - nmse: 0.0117 - val_loss: 3.2686 - val_nmse: 0.1993 - lr: 1.8129e-04\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1986 - nmse: 0.0116 - val_loss: 3.2418 - val_nmse: 0.1977 - lr: 1.7727e-04\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1947 - nmse: 0.0113 - val_loss: 3.2830 - val_nmse: 0.2002 - lr: 1.7329e-04\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1930 - nmse: 0.0113 - val_loss: 3.2508 - val_nmse: 0.1982 - lr: 1.6934e-04\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1916 - nmse: 0.0112 - val_loss: 3.2583 - val_nmse: 0.1987 - lr: 1.6543e-04\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1898 - nmse: 0.0114 - val_loss: 3.2715 - val_nmse: 0.1995 - lr: 1.6156e-04\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1887 - nmse: 0.0111 - val_loss: 3.2534 - val_nmse: 0.1984 - lr: 1.5773e-04\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1886 - nmse: 0.0109 - val_loss: 3.2697 - val_nmse: 0.1994 - lr: 1.5393e-04\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1876 - nmse: 0.0109 - val_loss: 3.2600 - val_nmse: 0.1988 - lr: 1.5017e-04\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1864 - nmse: 0.0109 - val_loss: 3.2542 - val_nmse: 0.1984 - lr: 1.4645e-04\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1877 - nmse: 0.0111 - val_loss: 3.2776 - val_nmse: 0.1999 - lr: 1.4276e-04\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1867 - nmse: 0.0110 - val_loss: 3.2475 - val_nmse: 0.1980 - lr: 1.3912e-04\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1861 - nmse: 0.0106 - val_loss: 3.2610 - val_nmse: 0.1988 - lr: 1.3552e-04\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1851 - nmse: 0.0108 - val_loss: 3.2696 - val_nmse: 0.1994 - lr: 1.3195e-04\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1849 - nmse: 0.0112 - val_loss: 3.2422 - val_nmse: 0.1977 - lr: 1.2843e-04\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1859 - nmse: 0.0109 - val_loss: 3.2777 - val_nmse: 0.1999 - lr: 1.2494e-04\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1845 - nmse: 0.0108 - val_loss: 3.2573 - val_nmse: 0.1986 - lr: 1.2150e-04\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1837 - nmse: 0.0106 - val_loss: 3.2729 - val_nmse: 0.1996 - lr: 1.1810e-04\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1834 - nmse: 0.0107 - val_loss: 3.2636 - val_nmse: 0.1990 - lr: 1.1474e-04\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1826 - nmse: 0.0105 - val_loss: 3.2575 - val_nmse: 0.1986 - lr: 1.1143e-04\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1830 - nmse: 0.0107 - val_loss: 3.2690 - val_nmse: 0.1993 - lr: 1.0815e-04\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1823 - nmse: 0.0104 - val_loss: 3.2529 - val_nmse: 0.1983 - lr: 1.0492e-04\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1819 - nmse: 0.0107 - val_loss: 3.2703 - val_nmse: 0.1994 - lr: 1.0174e-04\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1809 - nmse: 0.0106 - val_loss: 3.2586 - val_nmse: 0.1987 - lr: 9.8591e-05\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1821 - nmse: 0.0106 - val_loss: 3.2677 - val_nmse: 0.1993 - lr: 9.5491e-05\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1808 - nmse: 0.0106 - val_loss: 3.2636 - val_nmse: 0.1990 - lr: 9.2436e-05\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1806 - nmse: 0.0107 - val_loss: 3.2731 - val_nmse: 0.1996 - lr: 8.9425e-05\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1803 - nmse: 0.0106 - val_loss: 3.2655 - val_nmse: 0.1991 - lr: 8.6460e-05\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1797 - nmse: 0.0104 - val_loss: 3.2641 - val_nmse: 0.1990 - lr: 8.3539e-05\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1794 - nmse: 0.0106 - val_loss: 3.2693 - val_nmse: 0.1994 - lr: 8.0665e-05\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1789 - nmse: 0.0105 - val_loss: 3.2665 - val_nmse: 0.1992 - lr: 7.7836e-05\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1786 - nmse: 0.0104 - val_loss: 3.2693 - val_nmse: 0.1994 - lr: 7.5054e-05\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1782 - nmse: 0.0102 - val_loss: 3.2649 - val_nmse: 0.1991 - lr: 7.2318e-05\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1777 - nmse: 0.0105 - val_loss: 3.2604 - val_nmse: 0.1988 - lr: 6.9629e-05\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1777 - nmse: 0.0103 - val_loss: 3.2644 - val_nmse: 0.1991 - lr: 6.6987e-05\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1774 - nmse: 0.0106 - val_loss: 3.2714 - val_nmse: 0.1995 - lr: 6.4393e-05\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1776 - nmse: 0.0103 - val_loss: 3.2704 - val_nmse: 0.1994 - lr: 6.1847e-05\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1774 - nmse: 0.0106 - val_loss: 3.2616 - val_nmse: 0.1989 - lr: 5.9348e-05\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1772 - nmse: 0.0103 - val_loss: 3.2682 - val_nmse: 0.1993 - lr: 5.6898e-05\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1773 - nmse: 0.0104 - val_loss: 3.2683 - val_nmse: 0.1993 - lr: 5.4497e-05\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1772 - nmse: 0.0103 - val_loss: 3.2704 - val_nmse: 0.1994 - lr: 5.2144e-05\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1769 - nmse: 0.0105 - val_loss: 3.2634 - val_nmse: 0.1990 - lr: 4.9841e-05\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1763 - nmse: 0.0103 - val_loss: 3.2719 - val_nmse: 0.1995 - lr: 4.7586e-05\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1763 - nmse: 0.0103 - val_loss: 3.2689 - val_nmse: 0.1993 - lr: 4.5382e-05\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1760 - nmse: 0.0102 - val_loss: 3.2729 - val_nmse: 0.1996 - lr: 4.3227e-05\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1757 - nmse: 0.0104 - val_loss: 3.2658 - val_nmse: 0.1991 - lr: 4.1123e-05\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1758 - nmse: 0.0102 - val_loss: 3.2660 - val_nmse: 0.1991 - lr: 3.9068e-05\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1753 - nmse: 0.0100 - val_loss: 3.2706 - val_nmse: 0.1994 - lr: 3.7065e-05\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1752 - nmse: 0.0101 - val_loss: 3.2700 - val_nmse: 0.1994 - lr: 3.5112e-05\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1750 - nmse: 0.0104 - val_loss: 3.2696 - val_nmse: 0.1994 - lr: 3.3210e-05\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1749 - nmse: 0.0103 - val_loss: 3.2679 - val_nmse: 0.1993 - lr: 3.1359e-05\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1749 - nmse: 0.0102 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 2.9560e-05\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1748 - nmse: 0.0102 - val_loss: 3.2714 - val_nmse: 0.1995 - lr: 2.7812e-05\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1746 - nmse: 0.0102 - val_loss: 3.2694 - val_nmse: 0.1994 - lr: 2.6116e-05\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1746 - nmse: 0.0102 - val_loss: 3.2686 - val_nmse: 0.1993 - lr: 2.4472e-05\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1747 - nmse: 0.0101 - val_loss: 3.2736 - val_nmse: 0.1996 - lr: 2.2880e-05\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1744 - nmse: 0.0101 - val_loss: 3.2682 - val_nmse: 0.1993 - lr: 2.1340e-05\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1744 - nmse: 0.0104 - val_loss: 3.2658 - val_nmse: 0.1991 - lr: 1.9853e-05\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1744 - nmse: 0.0102 - val_loss: 3.2705 - val_nmse: 0.1994 - lr: 1.8419e-05\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1742 - nmse: 0.0100 - val_loss: 3.2728 - val_nmse: 0.1996 - lr: 1.7037e-05\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1741 - nmse: 0.0100 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 1.5708e-05\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1741 - nmse: 0.0103 - val_loss: 3.2673 - val_nmse: 0.1992 - lr: 1.4433e-05\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1740 - nmse: 0.0101 - val_loss: 3.2658 - val_nmse: 0.1991 - lr: 1.3211e-05\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1741 - nmse: 0.0103 - val_loss: 3.2678 - val_nmse: 0.1993 - lr: 1.2042e-05\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1739 - nmse: 0.0100 - val_loss: 3.2714 - val_nmse: 0.1995 - lr: 1.0926e-05\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1738 - nmse: 0.0103 - val_loss: 3.2723 - val_nmse: 0.1995 - lr: 9.8644e-06\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1738 - nmse: 0.0102 - val_loss: 3.2721 - val_nmse: 0.1995 - lr: 8.8564e-06\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1738 - nmse: 0.0102 - val_loss: 3.2715 - val_nmse: 0.1995 - lr: 7.9022e-06\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1737 - nmse: 0.0102 - val_loss: 3.2697 - val_nmse: 0.1994 - lr: 7.0020e-06\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1737 - nmse: 0.0103 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 6.1558e-06\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1737 - nmse: 0.0103 - val_loss: 3.2691 - val_nmse: 0.1993 - lr: 5.3638e-06\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1736 - nmse: 0.0099 - val_loss: 3.2704 - val_nmse: 0.1994 - lr: 4.6261e-06\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1736 - nmse: 0.0100 - val_loss: 3.2706 - val_nmse: 0.1994 - lr: 3.9426e-06\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1736 - nmse: 0.0101 - val_loss: 3.2703 - val_nmse: 0.1994 - lr: 3.3136e-06\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0103 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 2.7390e-06\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0103 - val_loss: 3.2697 - val_nmse: 0.1994 - lr: 2.2190e-06\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0103 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 1.7536e-06\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0102 - val_loss: 3.2702 - val_nmse: 0.1994 - lr: 1.3427e-06\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0104 - val_loss: 3.2701 - val_nmse: 0.1994 - lr: 9.8664e-07\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0103 - val_loss: 3.2699 - val_nmse: 0.1994 - lr: 6.8522e-07\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0101 - val_loss: 3.2699 - val_nmse: 0.1994 - lr: 4.3857e-07\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0100 - val_loss: 3.2699 - val_nmse: 0.1994 - lr: 2.4673e-07\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0105 - val_loss: 3.2699 - val_nmse: 0.1994 - lr: 1.0964e-07\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1735 - nmse: 0.0100 - val_loss: 3.2698 - val_nmse: 0.1994 - lr: 2.7418e-08\n",
      "Tiempo total de entrenamiento: 118.67 minutos.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardar modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio en donde se almacenara el modelo\n",
    "save_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/modelos_generados'\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Nombre del archivo del modelo\n",
    "model_name = 'unet_model_decay_coseno_with_normalization_zcore_5.keras'\n",
    "\n",
    "# Ruta completa del archivo\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir señal VSC a partir de una señal PAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Funcion para predecir con el modelo entrenado\n",
    "def predict_with_model(model, input_data):\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction\n",
    "\n",
    "# Cargar una matriz de entrada para hacer una predicción \n",
    "input_matrix = X[0:1] \n",
    "# Realizar la predicción\n",
    "predicted_output = predict_with_model(model, input_matrix)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(\"Predicción de la primera muestra de entrada:\")\n",
    "print(predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
