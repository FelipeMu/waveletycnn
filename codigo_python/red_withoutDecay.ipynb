{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias para trabajar con la red neuronal y procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "##################### Convertir matrices de .mat a .npy ##########################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_pam_mat' # matrices en formato .mat\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_vsc_mat' # matrices en formato .mat\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python' # INPUT PARA LA RED\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python' # OUTPUT O SALIDAS ESPERADAS PARA LA RED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, 31):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vsc_dir, output_vsc_dir, 'matrix_complex_vsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################<br>\n",
    "##################### Conversion a tensor tridimensional ##########################<br>\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python'\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python'\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para procesar las matrices complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_matriz_compleja(matriz_compleja):\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesar matrices complejas en la carpeta input_pam_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja\n",
    "        datos_organizados = procesar_matriz_compleja(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesar matrices complejas en la carpeta input_vsc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        output_path = os.path.join(output_vsc_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja\n",
    "        datos_organizados = procesar_matriz_compleja(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################<br>\n",
    "################## Verificacicon de \"shape\" - matrices pam y vsc ##################<br>\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsc_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_vsc = os.listdir(output_vsc_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsc = verificar_shape(output_vsc_dir_check, ejemplo_vsc)\n",
    "print(f\"Shape de {ejemplo_vsc} en {output_vsc_dir_check}: {shape_vsc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "####################### Red Neuronal Profunda: U-net #############################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_npy_files(input_pam_dir) # inputs\n",
    "Y = load_npy_files(output_vsc_dir) # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model_with_l2(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 500\n",
    "batchsize = 16\n",
    "learning_rate = 0.001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.3 # 70% entrenamiento & 30% validacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red\n",
    "#model = unet_model_with_l2(input_shape, l2_lambda)\n",
    "model = unet_model_with_l2(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myred",
   "language": "python",
   "name": "myred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
