{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias para trabajar con la red neuronal y procesamiento de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################<br>\n",
    "##################### Convertir matrices de .mat a .npy ##########################<br>\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_pam_mat' # matrices en formato .mat\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/matrices_complejas_vsc_mat' # matrices en formato .mat\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python' # INPUT PARA LA RED\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python' # OUTPUT O SALIDAS ESPERADAS PARA LA RED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos a analizar ->  50\n"
     ]
    }
   ],
   "source": [
    "total_files=sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de archivos a analizar -> \",total_files-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_files):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vsc_dir, output_vsc_dir, 'matrix_complex_vsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion a tensor tridimensional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_python'\n",
    "input_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_python'\n",
    "output_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vsc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################\n",
    "PREPROCESAMIENTO ANTES DE NORMALIZACIÓN DE MATRICES\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CÁLCULO DE LA MEDIA - PAM & VSC (la media se calcula teniendo en cuenta todas las matrices)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acumuladores para calcular la media de cada matriz (real e imaginaria) y la desviacion estandar\n",
    "\n",
    "#==========================\n",
    "#=== PAM SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_pam = 0\n",
    "media_real_pam = 0\n",
    "\n",
    "sumatoria_imag_pam = 0\n",
    "media_imag_pam = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_pam = 0\n",
    "sumatoria_imag_cuadrada_pam = 0\n",
    "\n",
    "desv_real_pam = 0\n",
    "desv_imag_pam = 0\n",
    "\n",
    "\n",
    "#==========================\n",
    "#=== VSC SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_vsc = 0\n",
    "media_real_vsc = 0\n",
    "\n",
    "sumatoria_imag_vsc = 0\n",
    "media_imag_vsc = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_vsc = 0\n",
    "sumatoria_imag_cuadrada_vsc = 0\n",
    "\n",
    "desv_real_vsc = 0\n",
    "desv_imag_vsc = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  PAM  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_real_pam(matriz):\n",
    "    global sumatoria_real_pam\n",
    "    sumatoria_real_pam = sumatoria_real_pam + np.sum(matriz)\n",
    "    #print(sumatoria_real_pam)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_real_cuadrada_pam(matriz):\n",
    "    global sumatoria_real_cuadrada_pam, media_real_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_pam = sumatoria_real_cuadrada_pam + (elemento - media_real_pam)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_imag_pam(matriz):\n",
    "    global sumatoria_imag_pam\n",
    "    sumatoria_imag_pam = sumatoria_imag_pam + np.sum(matriz)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_imag_cuadrada_pam(matriz):\n",
    "    global sumatoria_imag_cuadrada_pam, media_imag_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_pam = sumatoria_imag_cuadrada_pam + (elemento - media_imag_pam)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  VSC  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_real_vsc(matriz):\n",
    "    global sumatoria_real_vsc\n",
    "    sumatoria_real_vsc = sumatoria_real_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_real_cuadrada_vsc(matriz):\n",
    "    global sumatoria_real_cuadrada_vsc, media_real_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_vsc = sumatoria_real_cuadrada_vsc + (elemento - media_real_vsc)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_imag_vsc(matriz):\n",
    "    global sumatoria_imag_vsc\n",
    "    sumatoria_imag_vsc = sumatoria_imag_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_imag_cuadrada_vsc(matriz):\n",
    "    global sumatoria_imag_cuadrada_vsc, media_imag_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_vsc = sumatoria_imag_cuadrada_vsc + (elemento - media_imag_vsc)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA  MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_pam(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_pam(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a pam signals: Se suman cada unos de los coeficientes de cada matriz real pam (archivos x filas x columnas)\n",
    "num_files_input_pam_dir = sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.npy'))\n",
    "filas_matriz, columnas_matriz = matriz_compleja.shape\n",
    "coefs_totales =  num_files_input_pam_dir * filas_matriz * columnas_matriz # N\n",
    "media_real_pam = sumatoria_real_pam / coefs_totales # MEDIA REAL\n",
    "media_imag_pam = sumatoria_imag_pam / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_pam(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_pam(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_pam = np.square(sumatoria_real_cuadrada_pam/coefs_totales)\n",
    "desv_imag_pam = np.square(sumatoria_imag_cuadrada_pam/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#==============================================================================================================================\n",
    "#==============================================================================================================================\n",
    "#=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_vsc(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_vsc(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a vsc signals: Se suman cada unos de los coeficientes de cada matriz real vsc (archivos x filas x columnas)\n",
    "num_files_input_vsc_dir = sum(1 for filename in os.listdir(input_vsc_dir) if filename.endswith('.npy'))\n",
    "media_real_vsc = sumatoria_real_vsc / coefs_totales # MEDIA REAL\n",
    "media_imag_vsc = sumatoria_imag_vsc / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_vsc(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_vsc(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_vsc = np.square(sumatoria_real_cuadrada_vsc/coefs_totales)\n",
    "desv_imag_vsc = np.square(sumatoria_imag_cuadrada_vsc/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APLICACIÓN DE NORMALIZACION A LAS MATRICES PAM Y VSC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION MIN-MAX**\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_real_pam = 1000000\n",
    "min_imag_pam = 1000000\n",
    "max_real_pam = -100\n",
    "max_imag_pam = -100\n",
    "\n",
    "min_real_vsc = 1000000\n",
    "min_imag_vsc = 1000000\n",
    "max_real_vsc = -100\n",
    "max_imag_vsc = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PAM: encontrar min y max de matrices reales e imaginarias\n",
    "def encontrar_min_pam(matriz):\n",
    "    global min_real_pam, min_imag_pam\n",
    "    if np.min(matriz.real) < min_real_pam:\n",
    "        min_real_pam = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_pam:\n",
    "        min_imag_pam = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_pam(matriz):\n",
    "    global max_real_pam, max_imag_pam\n",
    "    if np.max(matriz.real) > max_real_pam:\n",
    "        max_real_pam = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_pam:\n",
    "        max_imag_pam = np.max(matriz.imag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "#VSC: encontrar min y max de matrices reales e imaginarias\n",
    "\n",
    "def encontrar_min_vsc(matriz):\n",
    "    global min_real_vsc, min_imag_vsc\n",
    "    if np.min(matriz.real) < min_real_vsc:\n",
    "        min_real_vsc = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_vsc:\n",
    "        min_imag_vsc = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_vsc(matriz):\n",
    "    global max_real_vsc, max_imag_vsc\n",
    "    if np.max(matriz.real) > max_real_vsc:\n",
    "        max_real_vsc = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_vsc:\n",
    "        max_imag_vsc = np.max(matriz.imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MIN-MAX\n",
    "#PAM\n",
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_pam(matriz_compleja)\n",
    "        encontrar_max_pam(matriz_compleja)\n",
    "\n",
    "#VSC\n",
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_vsc(matriz_compleja)\n",
    "        encontrar_max_vsc(matriz_compleja)\n",
    "        \n",
    "\n",
    "print(min_real_pam)\n",
    "print(min_imag_pam)\n",
    "print(max_real_pam)\n",
    "print(max_imag_pam)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(min_real_vsc)\n",
    "print(min_imag_vsc)\n",
    "print(max_real_vsc)\n",
    "print(max_imag_vsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION Z-CORE**\n",
    "##############################################################\n",
    "z = (x - u) / desv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_pam(matriz_compleja):\n",
    "    global media_real_pam, media_imag_pam, desv_real_pam, desv_imag_pam\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_pam) / desv_real_pam # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_pam) / desv_imag_pam # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_vsc(matriz_compleja):\n",
    "    global media_real_vsc, media_imag_vsc, desv_real_vsc, desv_imag_vsc\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_vsc) / desv_real_vsc # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_vsc) / desv_imag_vsc # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NORMALIZACIÓN MEDIANTE MIN - MAX**<br>\n",
    "Ni = (Xi - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz PAM)\n",
    "#Salida: n_real (matriz real de pam normalizada), n_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_pam(matriz_compleja):\n",
    "    global min_real_pam, max_real_pam, min_imag_pam, max_imag_pam\n",
    "    n_real = (matriz_compleja.real - min_real_pam) / (max_real_pam - min_real_pam)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_pam) / (max_imag_pam - min_imag_pam)\n",
    "    return n_real, n_imag\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz VSC)\n",
    "#Salida: n_real (matriz real de vsc normalizada), n_imag (matriz imag de vsc normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz vsc y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_vsc(matriz_compleja):\n",
    "    global min_real_vsc, max_real_vsc,  min_imag_vsc, max_imag_vsc\n",
    "    n_real = (matriz_compleja.real - min_real_vsc) / (max_real_vsc - min_real_vsc)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_vsc) / (max_imag_vsc - min_imag_vsc)\n",
    "    return n_real, n_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES SEGÚN UNA NORMALIZACIÓN Y ORGANIZAR DATOS PARA LA RED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz pam)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz pam y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_pam(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z = (x - u) / desv\n",
    "    #norm_real, norm_imag = normalizacion_pam(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi - Xmin) / (Xmax - Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_pam(matriz_compleja)\n",
    "\n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz vsc)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz vsc y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_vsc(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z=(x - u)/desv\n",
    "    #norm_real, norm_imag = normalizacion_vsc(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi-Xmin)/(Xmax-Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_vsc(matriz_compleja)\n",
    "    \n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_pam_dir y procesar matrices mediante una normalización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_pam(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vsc_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        output_path = os.path.join(output_vsc_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificacion de \"shape\" - matrices pam y vsc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir_check = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_pam_noise_1.npy en D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsc_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vsc_noise_1.npy en D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vsc = os.listdir(output_vsc_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsc = verificar_shape(output_vsc_dir_check, ejemplo_vsc)\n",
    "print(f\"Shape de {ejemplo_vsc} en {output_vsc_dir_check}: {shape_vsc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**|||Red Neuronal Profunda: U-net|||**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_pam_procesadas'\n",
    "output_vsc_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/matrices_complejas_vsc_procesadas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "     # verificar orden con que entrar los archivos en X e Y\n",
    "    file_names = [os.path.basename(f) for f in files]\n",
    "    print(f\"Archivos: {file_names}\\n\")\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE DATOS DE ENTRADAS Y SALIDAS PARA LA RED (X: INPUTS; Y: OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos: ['matrix_complex_pam_noise_1.npy', 'matrix_complex_pam_noise_10.npy', 'matrix_complex_pam_noise_11.npy', 'matrix_complex_pam_noise_12.npy', 'matrix_complex_pam_noise_13.npy', 'matrix_complex_pam_noise_14.npy', 'matrix_complex_pam_noise_15.npy', 'matrix_complex_pam_noise_16.npy', 'matrix_complex_pam_noise_17.npy', 'matrix_complex_pam_noise_18.npy', 'matrix_complex_pam_noise_19.npy', 'matrix_complex_pam_noise_2.npy', 'matrix_complex_pam_noise_20.npy', 'matrix_complex_pam_noise_21.npy', 'matrix_complex_pam_noise_22.npy', 'matrix_complex_pam_noise_23.npy', 'matrix_complex_pam_noise_24.npy', 'matrix_complex_pam_noise_25.npy', 'matrix_complex_pam_noise_26.npy', 'matrix_complex_pam_noise_27.npy', 'matrix_complex_pam_noise_28.npy', 'matrix_complex_pam_noise_29.npy', 'matrix_complex_pam_noise_3.npy', 'matrix_complex_pam_noise_30.npy', 'matrix_complex_pam_noise_31.npy', 'matrix_complex_pam_noise_32.npy', 'matrix_complex_pam_noise_33.npy', 'matrix_complex_pam_noise_34.npy', 'matrix_complex_pam_noise_35.npy', 'matrix_complex_pam_noise_36.npy', 'matrix_complex_pam_noise_37.npy', 'matrix_complex_pam_noise_38.npy', 'matrix_complex_pam_noise_39.npy', 'matrix_complex_pam_noise_4.npy', 'matrix_complex_pam_noise_40.npy', 'matrix_complex_pam_noise_41.npy', 'matrix_complex_pam_noise_42.npy', 'matrix_complex_pam_noise_43.npy', 'matrix_complex_pam_noise_44.npy', 'matrix_complex_pam_noise_45.npy', 'matrix_complex_pam_noise_46.npy', 'matrix_complex_pam_noise_47.npy', 'matrix_complex_pam_noise_48.npy', 'matrix_complex_pam_noise_49.npy', 'matrix_complex_pam_noise_5.npy', 'matrix_complex_pam_noise_50.npy', 'matrix_complex_pam_noise_6.npy', 'matrix_complex_pam_noise_7.npy', 'matrix_complex_pam_noise_8.npy', 'matrix_complex_pam_noise_9.npy']\n",
      "\n",
      "Archivos: ['matrix_complex_vsc_noise_1.npy', 'matrix_complex_vsc_noise_10.npy', 'matrix_complex_vsc_noise_11.npy', 'matrix_complex_vsc_noise_12.npy', 'matrix_complex_vsc_noise_13.npy', 'matrix_complex_vsc_noise_14.npy', 'matrix_complex_vsc_noise_15.npy', 'matrix_complex_vsc_noise_16.npy', 'matrix_complex_vsc_noise_17.npy', 'matrix_complex_vsc_noise_18.npy', 'matrix_complex_vsc_noise_19.npy', 'matrix_complex_vsc_noise_2.npy', 'matrix_complex_vsc_noise_20.npy', 'matrix_complex_vsc_noise_21.npy', 'matrix_complex_vsc_noise_22.npy', 'matrix_complex_vsc_noise_23.npy', 'matrix_complex_vsc_noise_24.npy', 'matrix_complex_vsc_noise_25.npy', 'matrix_complex_vsc_noise_26.npy', 'matrix_complex_vsc_noise_27.npy', 'matrix_complex_vsc_noise_28.npy', 'matrix_complex_vsc_noise_29.npy', 'matrix_complex_vsc_noise_3.npy', 'matrix_complex_vsc_noise_30.npy', 'matrix_complex_vsc_noise_31.npy', 'matrix_complex_vsc_noise_32.npy', 'matrix_complex_vsc_noise_33.npy', 'matrix_complex_vsc_noise_34.npy', 'matrix_complex_vsc_noise_35.npy', 'matrix_complex_vsc_noise_36.npy', 'matrix_complex_vsc_noise_37.npy', 'matrix_complex_vsc_noise_38.npy', 'matrix_complex_vsc_noise_39.npy', 'matrix_complex_vsc_noise_4.npy', 'matrix_complex_vsc_noise_40.npy', 'matrix_complex_vsc_noise_41.npy', 'matrix_complex_vsc_noise_42.npy', 'matrix_complex_vsc_noise_43.npy', 'matrix_complex_vsc_noise_44.npy', 'matrix_complex_vsc_noise_45.npy', 'matrix_complex_vsc_noise_46.npy', 'matrix_complex_vsc_noise_47.npy', 'matrix_complex_vsc_noise_48.npy', 'matrix_complex_vsc_noise_49.npy', 'matrix_complex_vsc_noise_5.npy', 'matrix_complex_vsc_noise_50.npy', 'matrix_complex_vsc_noise_6.npy', 'matrix_complex_vsc_noise_7.npy', 'matrix_complex_vsc_noise_8.npy', 'matrix_complex_vsc_noise_9.npy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = load_npy_files(input_pam_dir) # inputs\n",
    "Y = load_npy_files(output_vsc_dir) # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de los inputs (X): (50, 36, 1024, 2)\n",
      "Shape de los outputs (Y): (50, 36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**HIPERPARAMETROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pasos de decaimiento -> 300 pasos.\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batchsize = 8\n",
    "learning_rate = 0.001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.3 # 80% entrenamiento & 20% validacion\n",
    "\n",
    "\n",
    " # alpha: el lr min al que llegara el decaimiento sera el 10% del lr inicia\n",
    "alpha = 0.1\n",
    "# decay steps: Numero de pasos de entrenamiento tras los cuales el learning rate decaera desde su valor inicial hasta el valor final determinado por alpha\n",
    "decay_steps = 300#(int(X.shape[0]/batchsize))*max_epoch \n",
    "print(\"Total pasos de decaimiento ->\",decay_steps, \"pasos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREACIÓN DEL MODELO U-NET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red tensor X = [#inputs, columnas, filas, canales]. Se omite #inputs\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion decaimiento de coseno\n",
    "decay_cosine = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "def lr_schedule(X):\n",
    "    return float(decay_cosine(X))\n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.3568 - nmse: 0.9005 - val_loss: 0.3240 - val_nmse: 0.8535\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3282 - nmse: 0.8272 - val_loss: 0.3063 - val_nmse: 0.8066\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3143 - nmse: 0.7933 - val_loss: 0.2933 - val_nmse: 0.7724\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2978 - nmse: 0.7476 - val_loss: 0.2680 - val_nmse: 0.7056\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3157 - nmse: 0.8484 - val_loss: 0.3548 - val_nmse: 0.9344\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.3294 - nmse: 0.8273 - val_loss: 0.3048 - val_nmse: 0.8027\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.3162 - nmse: 0.7942 - val_loss: 0.2944 - val_nmse: 0.7754\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.3002 - nmse: 0.7572 - val_loss: 0.2774 - val_nmse: 0.7306\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.2847 - nmse: 0.7181 - val_loss: 0.2616 - val_nmse: 0.6889\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.2660 - nmse: 0.6686 - val_loss: 0.2421 - val_nmse: 0.6373\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.2463 - nmse: 0.6221 - val_loss: 0.2257 - val_nmse: 0.5940\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 27s 6s/step - loss: 0.2278 - nmse: 0.5746 - val_loss: 0.2056 - val_nmse: 0.5410\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2128 - nmse: 0.5406 - val_loss: 0.1938 - val_nmse: 0.5100\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1973 - nmse: 0.4863 - val_loss: 0.1780 - val_nmse: 0.4683\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1795 - nmse: 0.4404 - val_loss: 0.1630 - val_nmse: 0.4289\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.1669 - nmse: 0.4072 - val_loss: 0.1555 - val_nmse: 0.4088\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1592 - nmse: 0.3934 - val_loss: 0.1412 - val_nmse: 0.3714\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1474 - nmse: 0.3709 - val_loss: 0.1399 - val_nmse: 0.3675\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 35s 6s/step - loss: 0.1405 - nmse: 0.3505 - val_loss: 0.1288 - val_nmse: 0.3383\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.1327 - nmse: 0.3356 - val_loss: 0.1217 - val_nmse: 0.3197\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1280 - nmse: 0.3274 - val_loss: 0.1172 - val_nmse: 0.3081\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.1221 - nmse: 0.3069 - val_loss: 0.1136 - val_nmse: 0.2986\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1188 - nmse: 0.2986 - val_loss: 0.1080 - val_nmse: 0.2837\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1143 - nmse: 0.2845 - val_loss: 0.1084 - val_nmse: 0.2848\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1122 - nmse: 0.2901 - val_loss: 0.1060 - val_nmse: 0.2786\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1084 - nmse: 0.2717 - val_loss: 0.1008 - val_nmse: 0.2650\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1063 - nmse: 0.2666 - val_loss: 0.0991 - val_nmse: 0.2605\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1038 - nmse: 0.2608 - val_loss: 0.0942 - val_nmse: 0.2475\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0985 - nmse: 0.2487 - val_loss: 0.0924 - val_nmse: 0.2426\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0973 - nmse: 0.2414 - val_loss: 0.0948 - val_nmse: 0.2493\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0948 - nmse: 0.2299 - val_loss: 0.0911 - val_nmse: 0.2394\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0919 - nmse: 0.2259 - val_loss: 0.0872 - val_nmse: 0.2292\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0885 - nmse: 0.2264 - val_loss: 0.0827 - val_nmse: 0.2173\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0866 - nmse: 0.2215 - val_loss: 0.0847 - val_nmse: 0.2226\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.0840 - nmse: 0.2200 - val_loss: 0.0816 - val_nmse: 0.2145\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0820 - nmse: 0.2126 - val_loss: 0.0799 - val_nmse: 0.2099\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0787 - nmse: 0.1996 - val_loss: 0.0788 - val_nmse: 0.2072\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0774 - nmse: 0.2034 - val_loss: 0.0765 - val_nmse: 0.2009\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.0769 - nmse: 0.1990 - val_loss: 0.0815 - val_nmse: 0.2141\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.0738 - nmse: 0.1885 - val_loss: 0.0754 - val_nmse: 0.1981\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0698 - nmse: 0.1781 - val_loss: 0.0729 - val_nmse: 0.1918\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0679 - nmse: 0.1813 - val_loss: 0.0724 - val_nmse: 0.1906\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0646 - nmse: 0.1688 - val_loss: 0.0712 - val_nmse: 0.1871\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0620 - nmse: 0.1566 - val_loss: 0.0707 - val_nmse: 0.1859\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0595 - nmse: 0.1473 - val_loss: 0.0722 - val_nmse: 0.1898\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0565 - nmse: 0.1455 - val_loss: 0.0684 - val_nmse: 0.1798\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0542 - nmse: 0.1322 - val_loss: 0.0686 - val_nmse: 0.1804\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0521 - nmse: 0.1280 - val_loss: 0.0680 - val_nmse: 0.1789\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0497 - nmse: 0.1266 - val_loss: 0.0678 - val_nmse: 0.1782\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0484 - nmse: 0.1238 - val_loss: 0.0693 - val_nmse: 0.1821\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0466 - nmse: 0.1126 - val_loss: 0.0691 - val_nmse: 0.1817\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0453 - nmse: 0.1096 - val_loss: 0.0711 - val_nmse: 0.1870\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0428 - nmse: 0.1070 - val_loss: 0.0668 - val_nmse: 0.1755\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0396 - nmse: 0.1024 - val_loss: 0.0679 - val_nmse: 0.1784\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0379 - nmse: 0.0947 - val_loss: 0.0688 - val_nmse: 0.1806\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0361 - nmse: 0.0914 - val_loss: 0.0696 - val_nmse: 0.1828\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0346 - nmse: 0.0880 - val_loss: 0.0672 - val_nmse: 0.1764\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.0332 - nmse: 0.0865 - val_loss: 0.0697 - val_nmse: 0.1833\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 29s 5s/step - loss: 0.0316 - nmse: 0.0803 - val_loss: 0.0732 - val_nmse: 0.1925\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0304 - nmse: 0.0737 - val_loss: 0.0697 - val_nmse: 0.1830\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0283 - nmse: 0.0719 - val_loss: 0.0691 - val_nmse: 0.1815\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0271 - nmse: 0.0678 - val_loss: 0.0733 - val_nmse: 0.1925\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0261 - nmse: 0.0669 - val_loss: 0.0713 - val_nmse: 0.1874\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0254 - nmse: 0.0654 - val_loss: 0.0792 - val_nmse: 0.2082\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0260 - nmse: 0.0672 - val_loss: 0.0730 - val_nmse: 0.1917\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0246 - nmse: 0.0629 - val_loss: 0.0703 - val_nmse: 0.1846\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0238 - nmse: 0.0596 - val_loss: 0.0699 - val_nmse: 0.1834\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0225 - nmse: 0.0573 - val_loss: 0.0720 - val_nmse: 0.1889\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0221 - nmse: 0.0562 - val_loss: 0.0703 - val_nmse: 0.1848\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0207 - nmse: 0.0533 - val_loss: 0.0689 - val_nmse: 0.1810\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0199 - nmse: 0.0500 - val_loss: 0.0705 - val_nmse: 0.1852\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0190 - nmse: 0.0479 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0181 - nmse: 0.0464 - val_loss: 0.0693 - val_nmse: 0.1821\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0175 - nmse: 0.0435 - val_loss: 0.0719 - val_nmse: 0.1889\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0171 - nmse: 0.0429 - val_loss: 0.0703 - val_nmse: 0.1845\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0165 - nmse: 0.0416 - val_loss: 0.0687 - val_nmse: 0.1804\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0164 - nmse: 0.0415 - val_loss: 0.0711 - val_nmse: 0.1866\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0167 - nmse: 0.0426 - val_loss: 0.0737 - val_nmse: 0.1936\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0169 - nmse: 0.0428 - val_loss: 0.0752 - val_nmse: 0.1977\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0172 - nmse: 0.0437 - val_loss: 0.0733 - val_nmse: 0.1924\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0165 - nmse: 0.0423 - val_loss: 0.0740 - val_nmse: 0.1945\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0163 - nmse: 0.0411 - val_loss: 0.0686 - val_nmse: 0.1800\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0154 - nmse: 0.0384 - val_loss: 0.0698 - val_nmse: 0.1832\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0145 - nmse: 0.0362 - val_loss: 0.0711 - val_nmse: 0.1867\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0136 - nmse: 0.0347 - val_loss: 0.0723 - val_nmse: 0.1900\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0135 - nmse: 0.0346 - val_loss: 0.0731 - val_nmse: 0.1920\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0131 - nmse: 0.0332 - val_loss: 0.0705 - val_nmse: 0.1852\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0126 - nmse: 0.0328 - val_loss: 0.0713 - val_nmse: 0.1871\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0125 - nmse: 0.0312 - val_loss: 0.0721 - val_nmse: 0.1895\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0123 - nmse: 0.0314 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0127 - nmse: 0.0325 - val_loss: 0.0723 - val_nmse: 0.1898\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0119 - nmse: 0.0301 - val_loss: 0.0705 - val_nmse: 0.1853\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0120 - nmse: 0.0300 - val_loss: 0.0697 - val_nmse: 0.1830\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0115 - nmse: 0.0297 - val_loss: 0.0726 - val_nmse: 0.1906\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0127 - nmse: 0.0315 - val_loss: 0.0733 - val_nmse: 0.1925\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0125 - nmse: 0.0313 - val_loss: 0.0704 - val_nmse: 0.1850\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0128 - nmse: 0.0322 - val_loss: 0.0721 - val_nmse: 0.1893\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0129 - nmse: 0.0327 - val_loss: 0.0719 - val_nmse: 0.1888\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0115 - nmse: 0.0286 - val_loss: 0.0697 - val_nmse: 0.1832\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0113 - nmse: 0.0282 - val_loss: 0.0694 - val_nmse: 0.1822\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0107 - nmse: 0.0263 - val_loss: 0.0744 - val_nmse: 0.1955\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0109 - nmse: 0.0275 - val_loss: 0.0695 - val_nmse: 0.1826\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0105 - nmse: 0.0270 - val_loss: 0.0720 - val_nmse: 0.1892\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0101 - nmse: 0.0262 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0104 - nmse: 0.0265 - val_loss: 0.0702 - val_nmse: 0.1842\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0100 - nmse: 0.0249 - val_loss: 0.0719 - val_nmse: 0.1888\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0095 - nmse: 0.0248 - val_loss: 0.0704 - val_nmse: 0.1849\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 38s 8s/step - loss: 0.0095 - nmse: 0.0242 - val_loss: 0.0703 - val_nmse: 0.1847\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0091 - nmse: 0.0233 - val_loss: 0.0733 - val_nmse: 0.1926\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 34s 6s/step - loss: 0.0094 - nmse: 0.0245 - val_loss: 0.0738 - val_nmse: 0.1939\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0107 - nmse: 0.0270 - val_loss: 0.0688 - val_nmse: 0.1808\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0105 - nmse: 0.0263 - val_loss: 0.0706 - val_nmse: 0.1855\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0098 - nmse: 0.0252 - val_loss: 0.0735 - val_nmse: 0.1931\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0098 - nmse: 0.0247 - val_loss: 0.0731 - val_nmse: 0.1921\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0093 - nmse: 0.0239 - val_loss: 0.0710 - val_nmse: 0.1865\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0091 - nmse: 0.0232 - val_loss: 0.0714 - val_nmse: 0.1876\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0083 - nmse: 0.0212 - val_loss: 0.0711 - val_nmse: 0.1867\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0082 - nmse: 0.0207 - val_loss: 0.0712 - val_nmse: 0.1868\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0082 - nmse: 0.0202 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0083 - nmse: 0.0208 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0086 - nmse: 0.0214 - val_loss: 0.0707 - val_nmse: 0.1855\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0081 - nmse: 0.0206 - val_loss: 0.0723 - val_nmse: 0.1899\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0080 - nmse: 0.0207 - val_loss: 0.0714 - val_nmse: 0.1875\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0082 - nmse: 0.0203 - val_loss: 0.0707 - val_nmse: 0.1858\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0077 - nmse: 0.0196 - val_loss: 0.0731 - val_nmse: 0.1921\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0080 - nmse: 0.0206 - val_loss: 0.0717 - val_nmse: 0.1883\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0080 - nmse: 0.0196 - val_loss: 0.0710 - val_nmse: 0.1865\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0076 - nmse: 0.0191 - val_loss: 0.0720 - val_nmse: 0.1891\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0076 - nmse: 0.0189 - val_loss: 0.0696 - val_nmse: 0.1829\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0074 - nmse: 0.0187 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0071 - nmse: 0.0182 - val_loss: 0.0706 - val_nmse: 0.1855\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0069 - nmse: 0.0175 - val_loss: 0.0721 - val_nmse: 0.1894\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0068 - nmse: 0.0173 - val_loss: 0.0726 - val_nmse: 0.1908\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0071 - nmse: 0.0176 - val_loss: 0.0703 - val_nmse: 0.1847\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0071 - nmse: 0.0177 - val_loss: 0.0735 - val_nmse: 0.1932\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0072 - nmse: 0.0179 - val_loss: 0.0702 - val_nmse: 0.1844\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0070 - nmse: 0.0176 - val_loss: 0.0698 - val_nmse: 0.1832\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0068 - nmse: 0.0175 - val_loss: 0.0721 - val_nmse: 0.1893\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0072 - nmse: 0.0187 - val_loss: 0.0731 - val_nmse: 0.1920\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0070 - nmse: 0.0179 - val_loss: 0.0716 - val_nmse: 0.1880\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0070 - nmse: 0.0179 - val_loss: 0.0714 - val_nmse: 0.1875\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0068 - nmse: 0.0173 - val_loss: 0.0716 - val_nmse: 0.1880\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0066 - nmse: 0.0166 - val_loss: 0.0713 - val_nmse: 0.1874\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0065 - nmse: 0.0164 - val_loss: 0.0726 - val_nmse: 0.1906\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0064 - nmse: 0.0161 - val_loss: 0.0705 - val_nmse: 0.1852\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0061 - nmse: 0.0153 - val_loss: 0.0703 - val_nmse: 0.1846\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0062 - nmse: 0.0154 - val_loss: 0.0730 - val_nmse: 0.1917\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 27s 6s/step - loss: 0.0068 - nmse: 0.0173 - val_loss: 0.0710 - val_nmse: 0.1866\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0066 - nmse: 0.0169 - val_loss: 0.0740 - val_nmse: 0.1944\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 27s 6s/step - loss: 0.0066 - nmse: 0.0166 - val_loss: 0.0724 - val_nmse: 0.1901\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0065 - nmse: 0.0165 - val_loss: 0.0692 - val_nmse: 0.1816\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0066 - nmse: 0.0168 - val_loss: 0.0738 - val_nmse: 0.1937\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0070 - nmse: 0.0178 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.0064 - nmse: 0.0162 - val_loss: 0.0711 - val_nmse: 0.1866\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0062 - nmse: 0.0155 - val_loss: 0.0718 - val_nmse: 0.1886\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0059 - nmse: 0.0150 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0058 - nmse: 0.0149 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0058 - nmse: 0.0144 - val_loss: 0.0736 - val_nmse: 0.1933\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0060 - nmse: 0.0152 - val_loss: 0.0699 - val_nmse: 0.1835\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0059 - nmse: 0.0150 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0057 - nmse: 0.0143 - val_loss: 0.0740 - val_nmse: 0.1944\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0059 - nmse: 0.0151 - val_loss: 0.0699 - val_nmse: 0.1837\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0057 - nmse: 0.0149 - val_loss: 0.0720 - val_nmse: 0.1890\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0057 - nmse: 0.0144 - val_loss: 0.0739 - val_nmse: 0.1940\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0059 - nmse: 0.0147 - val_loss: 0.0721 - val_nmse: 0.1895\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 33s 6s/step - loss: 0.0055 - nmse: 0.0138 - val_loss: 0.0712 - val_nmse: 0.1871\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.0057 - nmse: 0.0142 - val_loss: 0.0729 - val_nmse: 0.1915\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.0056 - nmse: 0.0143 - val_loss: 0.0710 - val_nmse: 0.1863\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0059 - nmse: 0.0151 - val_loss: 0.0700 - val_nmse: 0.1837\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0062 - nmse: 0.0152 - val_loss: 0.0720 - val_nmse: 0.1890\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0069 - nmse: 0.0173 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0061 - nmse: 0.0153 - val_loss: 0.0721 - val_nmse: 0.1894\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0059 - nmse: 0.0149 - val_loss: 0.0729 - val_nmse: 0.1916\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0062 - nmse: 0.0157 - val_loss: 0.0691 - val_nmse: 0.1815\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0057 - nmse: 0.0148 - val_loss: 0.0718 - val_nmse: 0.1886\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.0053 - nmse: 0.0133 - val_loss: 0.0713 - val_nmse: 0.1873\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.0053 - nmse: 0.0133 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.0051 - nmse: 0.0126 - val_loss: 0.0703 - val_nmse: 0.1845\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0050 - nmse: 0.0127 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0049 - nmse: 0.0123 - val_loss: 0.0722 - val_nmse: 0.1898\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0051 - nmse: 0.0126 - val_loss: 0.0713 - val_nmse: 0.1874\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0048 - nmse: 0.0123 - val_loss: 0.0728 - val_nmse: 0.1912\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0052 - nmse: 0.0134 - val_loss: 0.0724 - val_nmse: 0.1901\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0054 - nmse: 0.0134 - val_loss: 0.0707 - val_nmse: 0.1856\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0053 - nmse: 0.0135 - val_loss: 0.0710 - val_nmse: 0.1865\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0053 - nmse: 0.0137 - val_loss: 0.0746 - val_nmse: 0.1961\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0058 - nmse: 0.0147 - val_loss: 0.0703 - val_nmse: 0.1846\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0048 - nmse: 0.0123 - val_loss: 0.0707 - val_nmse: 0.1859\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0046 - nmse: 0.0117 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0045 - nmse: 0.0114 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0046 - nmse: 0.0119 - val_loss: 0.0725 - val_nmse: 0.1904\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0047 - nmse: 0.0119 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0048 - nmse: 0.0124 - val_loss: 0.0735 - val_nmse: 0.1932\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0052 - nmse: 0.0131 - val_loss: 0.0736 - val_nmse: 0.1934\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0052 - nmse: 0.0132 - val_loss: 0.0699 - val_nmse: 0.1835\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0054 - nmse: 0.0136 - val_loss: 0.0720 - val_nmse: 0.1891\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0048 - nmse: 0.0120 - val_loss: 0.0701 - val_nmse: 0.1841\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0048 - nmse: 0.0122 - val_loss: 0.0715 - val_nmse: 0.1878\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0047 - nmse: 0.0120 - val_loss: 0.0702 - val_nmse: 0.1845\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0046 - nmse: 0.0117 - val_loss: 0.0722 - val_nmse: 0.1896\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0045 - nmse: 0.0113 - val_loss: 0.0713 - val_nmse: 0.1871\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0048 - nmse: 0.0123 - val_loss: 0.0714 - val_nmse: 0.1874\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0047 - nmse: 0.0117 - val_loss: 0.0701 - val_nmse: 0.1840\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0042 - nmse: 0.0107 - val_loss: 0.0709 - val_nmse: 0.1861\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0043 - nmse: 0.0109 - val_loss: 0.0709 - val_nmse: 0.1862\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0043 - nmse: 0.0108 - val_loss: 0.0707 - val_nmse: 0.1857\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0103 - val_loss: 0.0710 - val_nmse: 0.1864\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0040 - nmse: 0.0102 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0104 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0040 - nmse: 0.0100 - val_loss: 0.0694 - val_nmse: 0.1823\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0040 - nmse: 0.0102 - val_loss: 0.0724 - val_nmse: 0.1900\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0043 - nmse: 0.0111 - val_loss: 0.0706 - val_nmse: 0.1853\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0104 - val_loss: 0.0708 - val_nmse: 0.1858\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - nmse: 0.0099 - val_loss: 0.0710 - val_nmse: 0.1863\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0040 - nmse: 0.0103 - val_loss: 0.0705 - val_nmse: 0.1850\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0105 - val_loss: 0.0709 - val_nmse: 0.1861\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0104 - val_loss: 0.0711 - val_nmse: 0.1867\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0103 - val_loss: 0.0704 - val_nmse: 0.1849\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - nmse: 0.0098 - val_loss: 0.0706 - val_nmse: 0.1855\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0090 - val_loss: 0.0709 - val_nmse: 0.1862\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0036 - nmse: 0.0093 - val_loss: 0.0716 - val_nmse: 0.1881\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - nmse: 0.0101 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0046 - nmse: 0.0114 - val_loss: 0.0710 - val_nmse: 0.1864\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0041 - nmse: 0.0108 - val_loss: 0.0714 - val_nmse: 0.1874\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0046 - nmse: 0.0117 - val_loss: 0.0723 - val_nmse: 0.1897\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0043 - nmse: 0.0111 - val_loss: 0.0709 - val_nmse: 0.1864\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0045 - nmse: 0.0116 - val_loss: 0.0708 - val_nmse: 0.1859\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0045 - nmse: 0.0112 - val_loss: 0.0701 - val_nmse: 0.1840\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0040 - nmse: 0.0101 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0038 - nmse: 0.0096 - val_loss: 0.0696 - val_nmse: 0.1828\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0094 - val_loss: 0.0698 - val_nmse: 0.1834\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0040 - nmse: 0.0102 - val_loss: 0.0702 - val_nmse: 0.1844\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0038 - nmse: 0.0096 - val_loss: 0.0708 - val_nmse: 0.1860\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0040 - nmse: 0.0101 - val_loss: 0.0697 - val_nmse: 0.1830\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0041 - nmse: 0.0102 - val_loss: 0.0720 - val_nmse: 0.1892\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0038 - nmse: 0.0095 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.0702 - val_nmse: 0.1843\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0036 - nmse: 0.0092 - val_loss: 0.0710 - val_nmse: 0.1864\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0036 - nmse: 0.0088 - val_loss: 0.0693 - val_nmse: 0.1819\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0034 - nmse: 0.0085 - val_loss: 0.0718 - val_nmse: 0.1884\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0081 - val_loss: 0.0704 - val_nmse: 0.1848\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0083 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0032 - nmse: 0.0081 - val_loss: 0.0726 - val_nmse: 0.1907\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.0707 - val_nmse: 0.1856\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0035 - nmse: 0.0089 - val_loss: 0.0706 - val_nmse: 0.1853\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0033 - nmse: 0.0082 - val_loss: 0.0708 - val_nmse: 0.1859\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0034 - nmse: 0.0084 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0711 - val_nmse: 0.1867\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0076 - val_loss: 0.0696 - val_nmse: 0.1828\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0031 - nmse: 0.0075 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0029 - nmse: 0.0074 - val_loss: 0.0715 - val_nmse: 0.1877\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0030 - nmse: 0.0076 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0031 - nmse: 0.0080 - val_loss: 0.0714 - val_nmse: 0.1876\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0103 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0084 - val_loss: 0.0695 - val_nmse: 0.1824\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0093 - val_loss: 0.0729 - val_nmse: 0.1915\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0036 - nmse: 0.0089 - val_loss: 0.0696 - val_nmse: 0.1827\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0034 - nmse: 0.0086 - val_loss: 0.0718 - val_nmse: 0.1886\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0036 - nmse: 0.0090 - val_loss: 0.0699 - val_nmse: 0.1836\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0038 - nmse: 0.0098 - val_loss: 0.0728 - val_nmse: 0.1912\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0102 - val_loss: 0.0724 - val_nmse: 0.1900\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - nmse: 0.0097 - val_loss: 0.0700 - val_nmse: 0.1838\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0085 - val_loss: 0.0715 - val_nmse: 0.1877\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0035 - nmse: 0.0087 - val_loss: 0.0711 - val_nmse: 0.1868\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0083 - val_loss: 0.0709 - val_nmse: 0.1861\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0084 - val_loss: 0.0701 - val_nmse: 0.1841\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.0699 - val_nmse: 0.1837\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0030 - nmse: 0.0076 - val_loss: 0.0710 - val_nmse: 0.1864\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0715 - val_nmse: 0.1878\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0700 - val_nmse: 0.1839\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0715 - val_nmse: 0.1879\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0710 - val_nmse: 0.1866\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0079 - val_loss: 0.0698 - val_nmse: 0.1832\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0077 - val_loss: 0.0704 - val_nmse: 0.1849\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0707 - val_nmse: 0.1858\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - nmse: 0.0075 - val_loss: 0.0700 - val_nmse: 0.1837\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0724 - val_nmse: 0.1903\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.0701 - val_nmse: 0.1842\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - nmse: 0.0074 - val_loss: 0.0713 - val_nmse: 0.1873\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0069 - val_loss: 0.0705 - val_nmse: 0.1851\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0026 - nmse: 0.0067 - val_loss: 0.0692 - val_nmse: 0.1816\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0071 - val_loss: 0.0709 - val_nmse: 0.1863\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0070 - val_loss: 0.0713 - val_nmse: 0.1872\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0072 - val_loss: 0.0699 - val_nmse: 0.1837\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0032 - nmse: 0.0081 - val_loss: 0.0723 - val_nmse: 0.1898\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.0703 - val_nmse: 0.1845\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0025 - nmse: 0.0064 - val_loss: 0.0708 - val_nmse: 0.1859\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0027 - nmse: 0.0069 - val_loss: 0.0703 - val_nmse: 0.1847\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.0721 - val_nmse: 0.1893\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.0702 - val_nmse: 0.1844\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0027 - nmse: 0.0070 - val_loss: 0.0706 - val_nmse: 0.1855\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0072 - val_loss: 0.0718 - val_nmse: 0.1885\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0032 - nmse: 0.0082 - val_loss: 0.0716 - val_nmse: 0.1881\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0037 - nmse: 0.0092 - val_loss: 0.0695 - val_nmse: 0.1826\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - nmse: 0.0099 - val_loss: 0.0709 - val_nmse: 0.1862\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0041 - nmse: 0.0108 - val_loss: 0.0732 - val_nmse: 0.1923\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0051 - nmse: 0.0128 - val_loss: 0.0717 - val_nmse: 0.1883\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0048 - nmse: 0.0121 - val_loss: 0.0699 - val_nmse: 0.1835\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0035 - nmse: 0.0090 - val_loss: 0.0695 - val_nmse: 0.1825\n",
      "Tiempo total de entrenamiento: 132.00 minutos.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardar modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio en donde se almacenara el modelo\n",
    "save_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/modelos_generados'\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Nombre del archivo del modelo\n",
    "model_name = 'unet_model_decay_coseno_with_normalization_zcore_7.keras'\n",
    "\n",
    "# Ruta completa del archivo\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDECIR UNA SEÑAL VSC A PARTIR DE UNA SEÑAL PAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para predecir con el modelo entrenado\n",
    "def predict_with_model(model, input_data):\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una matriz de entrada para hacer una predicción \n",
    "input_matrix = X[0:1] \n",
    "\n",
    "# Realizar la predicción\n",
    "predicted_output = predict_with_model(model, input_matrix)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(\"Predicción de la primera muestra de entrada:\")\n",
    "print(predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
